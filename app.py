# -*- coding: utf-8 -*-
# Bibliograf√≠as especializadas ‚Äì UEB
# v7.4 ‚Äì auto-descarga, plantillas obligatorias, b√∫squeda estable,
# filtros/resultados/selecci√≥n/export, generador citas APA, keep-alive en procesos.

import io
import os
import re
import time
import json
import base64
import requests
import numpy as np
import pandas as pd
import streamlit as st
from unidecode import unidecode
from streamlit_autorefresh import st_autorefresh

# ----------------------------- Ajustes generales -----------------------------------

st.set_page_config(
    page_title="Herramienta para bibliograf√≠as",
    page_icon="üìö",
    layout="wide",
)

ss = st.session_state

# URLs oficiales (aj√∫stalas si cambian en tu web)
URL_DIGITAL = "https://biblioteca.unbosque.edu.co/sites/default/files/Formatos-Biblioteca/Biblioteca%20Colecci%C3%B3n%20Digital.xlsx"
URL_FISICA  = "https://biblioteca.unbosque.edu.co/sites/default/files/Formatos-Biblioteca/Biblioteca%20BD%20Colecci%C3%B3n%20F%C3%ADsica.xlsx"

# Nombres de columnas "est√°ndar" preferidas
COL_TITULO            = "T√≠tulo"
COL_TEMATICAS         = "Tem√°ticas"
COL_TIPO_ITEM         = "Tipo de √≠tem"
COL_TIPO_ITEM_NORM    = "Tipo de √≠tem normalizado mat especial"
COL_EDITORIAL         = "Editorial"
COL_AUTORES           = "Autor(es)"
COL_ANIO              = "A√±o de Publicaci√≥n"
COL_BASE_DATOS        = "Base de datos"
COL_URL_OA            = "Url OA"
COL_URL_FISICA        = "Url en LOCATE/IDEA"     # F√≠sico; lo normalizaremos a "Url de acceso"
COL_URL_ACCESO_STD    = "Url de acceso"          # Unificaci√≥n para Digital/F√≠sica
COL_NO_TOPO           = "No. Topogr√°fico"
COL_ISSN1             = "ISSN1"
COL_ISBN              = "ISBN"
COL_SJR               = "Clasificaci√≥n SJR"
COL_PERM_LOC          = "permanent_location.name"
COL_BARCODE           = "Item Barcode"
COL_FORMATO           = "Formato"

# Por defecto para duplicados
DEF_DUP_DIGITAL = "Url OA"
DEF_DUP_FISICA  = "No. Topogr√°fico"

# -------------------------------- Utilidades ----------------------------------------

def _norm_text(s):
    """Normaliza para comparaci√≥n (lower + unidecode + quita espacios dobles)."""
    if s is None:
        return ""
    s = str(s)
    s = s.replace("\n", " ").strip()
    s = unidecode(s.lower())
    s = re.sub(r"\s+", " ", s)
    return s

@st.cache_data(ttl=3600, show_spinner=False)
def download_with_resume(url, label="archivo", timeout=60):
    """Descarga con requests, cacheada, devuelve BytesIO."""
    r = requests.get(url, timeout=timeout)
    r.raise_for_status()
    bio = io.BytesIO(r.content)
    bio.seek(0)
    return bio

@st.cache_data(ttl=3600, show_spinner=False)
def read_excel_from_bytes(bio, sheet=None):
    """Lee Excel desde BytesIO a DataFrame."""
    df = pd.read_excel(bio, sheet_name=sheet)
    return df

def normalize_physical_columns(df):
    """Normaliza columnas de F√≠sico: unifica URL, etc."""
    if COL_URL_FISICA in df.columns:
        df[COL_URL_ACCESO_STD] = df[COL_URL_FISICA]
    if COL_URL_OA in df.columns and COL_URL_ACCESO_STD not in df.columns:
        df[COL_URL_ACCESO_STD] = df[COL_URL_OA]
    if COL_URL_ACCESO_STD not in df.columns:
        df[COL_URL_ACCESO_STD] = ""
    return df

def normalize_digital_columns(df):
    """Normaliza columnas de Digital a URL est√°ndar."""
    if COL_URL_OA in df.columns:
        df[COL_URL_ACCESO_STD] = df[COL_URL_OA]
    else:
        df[COL_URL_ACCESO_STD] = ""
    return df

def show_info_panel():
    st.markdown(
        """
### ‚ÑπÔ∏è Informaci√≥n

- **Objetivo**: permitir la autogesti√≥n por programa/asignatura/tema y resaltar **t√©rminos a excluir** para depuraci√≥n manual.  
- Usa siempre las **bases oficiales** (Digital/F√≠sica) o s√∫belas **manualmente** en la barra lateral.  
- **Plantillas**: [Tem√°ticas](https://biblioteca.unbosque.edu.co/sites/default/files/Formatos-Biblioteca/Plantilla%20Tem%C3%A1ticas.xlsx) y [T√©rminos a excluir](https://biblioteca.unbosque.edu.co/sites/default/files/Formatos-Biblioteca/Plantilla%20T%C3%A9rminos%20a%20excluir.xlsx).  
- Los archivos adjuntos **no se almacenan** por la Universidad y se eliminan al cerrar la app.  
- El proceso puede tardar algunos minutos; **puedes seguir usando tu equipo** (no cierres el navegador).
        """,
        help="Gu√≠a de uso"
    )

def keepalive_if_working():
    # Activa un refresh suave solo si hay tareas largas en curso
    if ss.get("loading_digital") or ss.get("processing_digital") or ss.get("loading_fisica") or ss.get("processing_fisica"):
        st_autorefresh(interval=45000, key="keepalive")

# ----------------------------- Sidebar (plantillas & manual) ------------------------

def sidebar():
    with st.sidebar:
        st.image(
            "https://biblioteca.unbosque.edu.co/sites/default/files/Logos/Logo%201%20Blanco.png",
            use_container_width=True
        )
        st.caption("Biblioteca Juan Roa V√°squez")

        st.markdown("### Plantillas oficiales:")
        st.markdown("- [Tem√°ticas](https://biblioteca.unbosque.edu.co/sites/default/files/Formatos-Biblioteca/Plantilla%20Tem%C3%A1ticas.xlsx)")
        st.markdown("- [T√©rminos a excluir](https://biblioteca.unbosque.edu.co/sites/default/files/Formatos-Biblioteca/Plantilla%20T%C3%A9rminos%20a%20excluir.xlsx)")

        st.markdown("### Archivos auxiliares (obligatorios)")
        tem_file = st.file_uploader("Tem√°ticas (.xlsx, col1=t√©rmino, col2=normalizado)", type=["xlsx"], key="up_temas")
        exc_file = st.file_uploader("T√©rminos a excluir (.xlsx, 1ra columna)", type=["xlsx"], key="up_excluir")

        st.markdown("---")
        with st.expander("üîß Avanzado: subir bases Digital/F√≠sica manualmente"):
            man_dig = st.file_uploader("Base de datos de la colecci√≥n **Digital** (.xlsx)", type=["xlsx"], key="up_dig")
            man_fis = st.file_uploader("Base de datos de la colecci√≥n **F√≠sica** (.xlsx)", type=["xlsx"], key="up_fis")

        st.info(
            "Por defecto se descargan **bases oficiales** autom√°ticamente. "
            "Puedes subir manualmente una base en el panel **Avanzado** si lo necesitas."
        )

        return tem_file, exc_file, man_dig, man_fis

# ------------------------------ Carga autom√°tica bases --------------------------------

def ensure_bases_loaded(man_dig, man_fis):
    """Garantiza que Digital/F√≠sica est√©n en memoria. Soporta manual y oficial."""
    # Keepalive mientras se trabaja
    keepalive_if_working()

    if "df_digital" not in ss:
        ss.df_digital = None
    if "df_fisica" not in ss:
        ss.df_fisica = None

    # Manual tiene prioridad si se sube
    if man_dig is not None:
        try:
            ss.loading_digital = True
            df = pd.read_excel(man_dig)
            ss.df_digital = normalize_digital_columns(df)
            ss.loading_digital = False
            st.success("Base de datos de la colecci√≥n **Digital** (manual) cargada en memoria.")
        except Exception as e:
            ss.loading_digital = False
            st.error(f"No se pudo leer la base Digital manual: {e}")

    if man_fis is not None:
        try:
            ss.loading_fisica = True
            df = pd.read_excel(man_fis)
            ss.df_fisica = normalize_physical_columns(df)
            ss.loading_fisica = False
            st.success("Base de datos de la colecci√≥n **F√≠sica** (manual) cargada en memoria.")
        except Exception as e:
            ss.loading_fisica = False
            st.error(f"No se pudo leer la base F√≠sica manual: {e}")

    # Si alguna falta, descarga oficial
    if ss.df_digital is None:
        ss.loading_digital = True
        with st.status("Descargando **Base de datos de la colecci√≥n Digital**‚Ä¶", expanded=True):
            try:
                bio = download_with_resume(URL_DIGITAL, "Digital")
                dd = read_excel_from_bytes(bio)
                ss.df_digital = normalize_digital_columns(dd)
                st.write("Descarga completa. Verificando archivo‚Ä¶")
                time.sleep(0.4)
                st.success("Base de datos de la colecci√≥n Digital lista ‚úÖ")
            except Exception as e:
                st.error(f"No fue posible descargar la base Digital: {e}")
            finally:
                ss.loading_digital = False

    if ss.df_fisica is None:
        ss.loading_fisica = True
        with st.status("Descargando **Base de datos de la colecci√≥n F√≠sica**‚Ä¶", expanded=True):
            try:
                bio = download_with_resume(URL_FISICA, "F√≠sica")
                df = read_excel_from_bytes(bio)
                ss.df_fisica = normalize_physical_columns(df)
                st.write("Descarga completa. Verificando archivo‚Ä¶")
                time.sleep(0.4)
                st.success("Base de datos de la colecci√≥n F√≠sica lista ‚úÖ")
            except Exception as e:
                st.error(f"No fue posible descargar la base F√≠sica: {e}")
            finally:
                ss.loading_fisica = False

    # Se√±al de listo
    if ss.df_digital is not None and ss.df_fisica is not None:
        st.success("‚úÖ Bases oficiales listas en memoria.")
        return True
    return False

# -------------------------------- B√∫squeda -------------------------------------------

def build_term_list(df_tematicas):
    """
    Construye lista de tuplas (patr√≥n_busqueda, normalizado).
    df_tematicas: 2 columnas: col0 = t√©rmino, col1 = normalizado.
    """
    terms = []
    if df_tematicas is None or df_tematicas.empty:
        return terms
    cols = df_tematicas.columns.tolist()
    tcol = cols[0]
    ncol = cols[1] if len(cols) > 1 else cols[0]
    for _, row in df_tematicas.iterrows():
        term = str(row.get(tcol, "")).strip()
        norm = str(row.get(ncol, "")).strip() or term
        if term:
            terms.append((term, norm))
    return terms

def build_exclusion_list(df_excluir):
    """Obtiene lista de t√©rminos a excluir de la primera columna."""
    if df_excluir is None or df_excluir.empty:
        return []
    col = df_excluir.columns[0]
    vals = []
    for x in df_excluir[col].tolist():
        s = str(x).strip()
        if s:
            vals.append(s.lower())
    return vals

def col_exists(df, name):
    return name in df.columns

def run_search(
    df_dig,
    df_fis,
    df_temas,
    df_excluir,
    col1_busq=COL_TITULO,
    col2_busq=COL_TEMATICAS,
    col_dup_dig=DEF_DUP_DIGITAL,
    col_dup_fis=DEF_DUP_FISICA,
):
    """
    Busca por tem√°ticas (t√©rminos y normalizados) en Digital + F√≠sica, excluye por lista,
    agrega 'Tem√°tica normalizada' y 'Fuente' (Digital/F√≠sica), y deduplica por columnas elegidas.
    Devuelve (df_resultados, df_bitacora[term, resultados]).
    """
    # Verificaciones m√≠nimas
    if df_dig is None or df_fis is None:
        raise ValueError("Faltan bases en memoria.")
    for df, nm in [(df_dig, "Digital"), (df_fis, "F√≠sica")]:
        if not col_exists(df, col1_busq):
            raise ValueError(f"En {nm} no existe la columna '{col1_busq}'.")
        if not col_exists(df, col2_busq):
            raise ValueError(f"En {nm} no existe la columna '{col2_busq}'.")

    # Listas de t√©rminos
    terms = build_term_list(df_temas)
    excl  = build_exclusion_list(df_excluir)

    # Pre-normaliza campos de b√∫squeda
    def add_norms(df):
        df = df.copy()
        df["_n1"] = df[col1_busq].apply(_norm_text)
        df["_n2"] = df[col2_busq].apply(_norm_text)
        return df

    dig = add_norms(df_dig)
    fis = add_norms(df_fis)

    # Unifico URL de acceso
    if COL_URL_ACCESO_STD not in dig.columns:
        if COL_URL_OA in dig.columns:
            dig[COL_URL_ACCESO_STD] = dig[COL_URL_OA]
        else:
            dig[COL_URL_ACCESO_STD] = ""
    if COL_URL_ACCESO_STD not in fis.columns:
        if COL_URL_FISICA in fis.columns:
            fis[COL_URL_ACCESO_STD] = fis[COL_URL_FISICA]
        else:
            fis[COL_URL_ACCESO_STD] = ""

    # Matching
    results = []
    bitacora = []
    for (term, norm) in terms:
        patt = _norm_text(term)
        # Digital
        cd = dig[(dig["_n1"].str.contains(patt, na=False)) | (dig["_n2"].str.contains(patt, na=False))].copy()
        if not cd.empty:
            cd["Tem√°tica normalizada"] = norm
            cd["Fuente"] = "Digital"
            results.append(cd)
            bitacora.append(("Digital", norm, len(cd)))
        # F√≠sica
        cf = fis[(fis["_n1"].str.contains(patt, na=False)) | (fis["_n2"].str.contains(patt, na=False))].copy()
        if not cf.empty:
            cf["Tem√°tica normalizada"] = norm
            cf["Fuente"] = "F√≠sica"
            results.append(cf)
            bitacora.append(("F√≠sica", norm, len(cf)))

    if not results:
        return pd.DataFrame(), pd.DataFrame(columns=["Fuente", "T√©rmino", "Resultados"])

    all_ = pd.concat(results, ignore_index=True)

    # Exclusi√≥n
    if excl:
        patt_ex = "|".join([re.escape(x) for x in excl])
        mask_ex = all_["_n1"].str.contains(patt_ex, na=False) | all_["_n2"].str.contains(patt_ex, na=False)
        all_ = all_.loc[~mask_ex].copy()

    # Deduplicaci√≥n por fuente
    # Digital
    if col_exists(all_, col_dup_dig):
        dup_d = all_["Fuente"].eq("Digital") & all_[col_dup_dig].notna()
        all_.loc[dup_d, "_dedup_key"] = all_.loc[dup_d, col_dup_dig].astype(str)
    else:
        all_["_dedup_key"] = np.nan

    # F√≠sica
    if col_exists(all_, col_dup_fis):
        dup_f = all_["Fuente"].eq("F√≠sica") & all_[col_dup_fis].notna()
        all_.loc[dup_f, "_dedup_key_f"] = all_.loc[dup_f, col_dup_fis].astype(str)
    else:
        all_["_dedup_key_f"] = np.nan

    # Drop dup dentro de cada fuente
    before = len(all_)
    dmask = all_["Fuente"].eq("Digital")
    fmask = all_["Fuente"].eq("F√≠sica")
    all_ = pd.concat([
        all_.loc[dmask].drop_duplicates(subset=[col_dup_dig]) if col_exists(all_, col_dup_dig) else all_.loc[dmask],
        all_.loc[fmask].drop_duplicates(subset=[col_dup_fis]) if col_exists(all_, col_dup_fis) else all_.loc[fmask]
    ], ignore_index=True)
    after = len(all_)
    # Limpieza columnas auxiliares
    all_.drop(columns=["_n1", "_n2", "_dedup_key", "_dedup_key_f"], errors="ignore", inplace=True)

    # Bit√°cora
    bit = pd.DataFrame(bitacora, columns=["Fuente", "T√©rmino", "Resultados"])
    bit = (bit.groupby(["Fuente", "T√©rmino"], as_index=False)["Resultados"]
           .sum()
           .sort_values(["Fuente", "Resultados"], ascending=[True, False]))

    return all_, bit

# ------------------------------ Citas APA -------------------------------------------

def apa_authors(raw):
    """Heur√≠stica: 'P√©rez, Juan; L√≥pez, Ana' o 'Juan P√©rez; Ana L√≥pez' -> 'P√©rez, J., & L√≥pez, A.'"""
    if not raw or str(raw).strip().upper() == "NO APLICA":
        return ""
    parts = re.split(r";\s*", str(raw).strip())
    out = []
    for p in parts:
        p = p.strip()
        if not p:
            continue
        if "," in p:
            ap, nm = p.split(",", 1)
            ap = ap.strip()
            nm = nm.strip()
            ini = " ".join([f"{x[0]}." for x in nm.split() if x])
            out.append(f"{ap}, {ini}")
        else:
            toks = p.split()
            if len(toks) >= 2:
                ap = toks[-1]
                ini = " ".join([f"{x[0]}." for x in toks[:-1] if x])
                out.append(f"{ap}, {ini}")
            else:
                out.append(p)
    if not out:
        return ""
    if len(out) == 1:
        return out[0]
    if len(out) == 2:
        return f"{out[0]} & {out[1]}"
    return ", ".join(out[:-1]) + f", & {out[-1]}"

def apa_year(raw):
    """Usa texto; si NO APLICA -> vac√≠o; si viene otro texto sin a√±o v√°lido, respeta 's.f.' si ya se puso en la base."""
    if raw is None:
        return ""
    s = str(raw).strip()
    if s.upper() == "NO APLICA":
        return ""
    return s  # ya viene con s.f. si aplica

def coalesce(row, *names):
    for n in names:
        if n in row and str(row[n]).strip():
            return str(row[n]).strip()
    return ""

def format_apa_row(row):
    """
    Reglas dadas:
    - T√≠tulo (obligatorio)
    - Autor(es) opcional (omite si 'NO APLICA')
    - Editorial: obligatorio en teor√≠a; si falta -> 's. e.'
    - A√±o de Publicaci√≥n: texto; 'NO APLICA' -> vac√≠o; 's.f.' est√° permitido (viene de origen).
    - Base de datos: incluir siempre 'T√≠tulo disponible en ‚Ä¶'
    - Url de acceso: **siempre** (Digital) / unificado (F√≠sico)
    - ISBN / ISSN1 si existen (no 'NO APLICA'), tras 'T√≠tulo disponible en ‚Ä¶'
    - F√≠sico: a√±adir 'T√≠tulo disponible en f√≠sico, No Topogr√°fico: ‚Ä¶'
    - No se incluyen Tem√°ticas, SJR, etc.
    - Tipolog√≠as normalizadas (‚ÄúMaterial especial‚Äù, ‚ÄúMaterial did√°ctico‚Äù) -> cita gen√©rica.
    """
    fuente = row.get("Fuente", "")
    tipo_norm = row.get(COL_TIPO_ITEM_NORM, "")
    tipo = row.get(COL_TIPO_ITEM, "")

    titulo = str(row.get(COL_TITULO, "")).strip().rstrip(".")
    if not titulo:
        return ""

    autores = apa_authors(row.get(COL_AUTORES, ""))
    editorial = row.get(COL_EDITORIAL, "").strip()
    if not editorial:
        editorial = "s. e."
    anio = apa_year(row.get(COL_ANIO, ""))

    base_datos = row.get(COL_BASE_DATOS, "").strip()
    url = coalesce(row, COL_URL_ACCESO_STD, COL_URL_OA, COL_URL_FISICA)
    isbn = row.get(COL_ISBN, "")
    issn = row.get(COL_ISSN1, "")
    if str(isbn).upper() == "NO APLICA":
        isbn = ""
    if str(issn).upper() == "NO APLICA":
        issn = ""
    topo = row.get(COL_NO_TOPO, "")

    # Autores + (A√±o). T√≠tulo. Editorial.
    pref = ""
    if autores:
        pref += f"{autores} "
    if anio:
        pref += f"({anio}). "
    elif autores:
        pref += "(s. f.). "
    # Si no hubo autores ni a√±o, no ponemos (s.f.) para no ‚Äúensuciar‚Äù referencias de Govt/Corp sin a√±o claro:
    elif not autores:
        pref += ""

    core = f"{pref}{titulo}. {editorial}."

    # Disponibilidad
    disp = ""
    if str(fuente).lower().startswith("f√≠s"):
        # F√≠sico
        disp = " T√≠tulo disponible en f√≠sico"
        if topo:
            disp += f", No Topogr√°fico: {topo}"
        disp += "."
        if url:
            disp += f" {url}"
    else:
        # Digital
        if base_datos:
            disp = f" T√≠tulo disponible en {base_datos}."
        else:
            disp = " T√≠tulo disponible en plataforma digital."
        if url:
            disp += f" {url}"

    # Identificadores
    ident = ""
    if isbn:
        ident += f" ISBN: {isbn}."
    if issn:
        ident += f" ISSN: {issn}."

    # Material especial / did√°ctico -> no cambia formateo, solo caemos en gen√©rico (ya lo es)
    return " ".join((core + disp + (" " + ident if ident else "")).split())

# ------------------------------ Resultados / UI --------------------------------------

def render_results_ui(df_result):
    st.subheader("Resultados")
    if df_result is None or df_result.empty:
        st.info("A√∫n no hay resultados. Ejecuta la b√∫squeda.")
        return

    res0 = df_result.copy()

    # Filtros
    cfa, cfb, cfc = st.columns([1.2, 1.2, 1])
    tipos_col = COL_TIPO_ITEM if COL_TIPO_ITEM in res0.columns else None
    if tipos_col:
        tipos = sorted([t for t in res0[tipos_col].dropna().unique() if str(t).strip()])
        sel_tipos = cfa.multiselect("Filtrar por **Tipo de √≠tem**", tipos, default=tipos)
    else:
        sel_tipos = None

    tema_norm_col = "Tem√°tica normalizada" if "Tem√°tica normalizada" in res0.columns else None
    if tema_norm_col:
        tnorms = sorted([t for t in res0[tema_norm_col].dropna().unique() if str(t).strip()])
        sel_tnorms = cfb.multiselect("Filtrar por **Tem√°tica normalizada**", tnorms, default=tnorms)
    else:
        sel_tnorms = None

    limit_view = cfc.number_input("Filas a mostrar (vista)", min_value=50, max_value=20000, value=800, step=50)

    filt = res0
    if sel_tipos is not None:
        filt = filt[filt[tipos_col].isin(sel_tipos)]
    if sel_tnorms is not None:
        filt = filt[filt[tema_norm_col].isin(sel_tnorms)]

    st.caption("Marca las filas para exportar **solo seleccionadas**, de lo contrario se exportar√° todo lo filtrado.")
    show = filt.copy()
    show.insert(0, "‚úî", False)
    view = show.head(int(limit_view)).copy()

    edited = st.data_editor(
        view,
        use_container_width=True,
        height=520,
        column_config={"‚úî": st.column_config.CheckboxColumn("Seleccionar")},
        hide_index=True,
        num_rows="fixed",
    )

    selected_ids = edited.index[edited["‚úî"]].tolist()
    selected = view.loc[selected_ids].drop(columns=["‚úî"], errors="ignore")
    export_df = selected if not selected.empty else filt.copy()

    col_exp1, col_exp2, col_exp3 = st.columns([1, 1, 1])

    with col_exp1:
        st.download_button(
            "‚¨áÔ∏è CSV (filtrado/seleccionado)",
            data=export_df.fillna("").to_csv(index=False).encode("utf-8"),
            file_name="resultados_filtrados.csv",
            mime="text/csv",
            use_container_width=True,
        )

    with col_exp2:
        xbio = io.BytesIO()
        writer = pd.ExcelWriter(xbio, engine="xlsxwriter")
        # Dejar columnas ‚Äúadministrativas‚Äù tambi√©n en Excel:
        export_df.to_excel(writer, index=False, sheet_name="Datos")
        writer.close()
        xbio.seek(0)
        st.download_button(
            "‚¨áÔ∏è Excel (filtrado/seleccionado)",
            data=xbio.getvalue(),
            file_name="resultados_filtrados.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )

    # Citas APA (TXT)
    citas = []
    for _, r in export_df.iterrows():
        citas.append(format_apa_row(r))
    txt = "\n\n".join([c for c in citas if c]) if citas else "Sin filas seleccionadas/filtradas."

    with col_exp3:
        st.download_button(
            "üìù Citas APA (TXT)",
            data=txt.encode("utf-8"),
            file_name="citas_apa.txt",
            mime="text/plain",
            use_container_width=True,
        )

    # Vista previa (opcional)
    st.caption(f"Vista previa de {len(view)} filas (de {len(filt)} filtradas).")
    st.dataframe(view.drop(columns=["‚úî"], errors="ignore"), use_container_width=True, height=350)

# ------------------------------ App main --------------------------------------------

def main():
    # Estado
    if "results_df" not in ss:
        ss.results_df = None
    if "bitacora_df" not in ss:
        ss.bitacora_df = None

    tem_file, exc_file, man_dig, man_fis = sidebar()

    st.markdown("## Herramienta para la elaboraci√≥n de bibliograf√≠as especializadas")
    show_info_panel()

    # Descarga/carga bases
    listo = ensure_bases_loaded(man_dig, man_fis)

    # Mientras ‚Äútrabaja‚Äù, mant√©n vivo:
    keepalive_if_working()

    # Si a√∫n no est√°n listas, no muestres UI dependiente
    if not listo:
        st.warning("Cargando las bases Digital y F√≠sica desde la web oficial‚Ä¶ Puedes subir **Tem√°ticas** y **T√©rminos a excluir** mientras tanto. No cierres esta ventana.")
        return

    # Mostrar panel de ‚ÄúBases listas‚Äù
    with st.container(border=True):
        st.subheader("Bases oficiales cargadas en memoria (sesi√≥n)")
        st.markdown(f"- Base de datos de la colecci√≥n **Digital**")
        st.markdown(f"- Base de datos de la colecci√≥n **F√≠sica**")

    st.markdown("### Configuraci√≥n de b√∫squeda y duplicados")

    # Defaults con fallback si faltan
    dig_cols = ss.df_digital.columns.tolist()
    fis_cols = ss.df_fisica.columns.tolist()

    # Selects
    col1, col2, col3, col4 = st.columns([1.1, 1.1, 1.2, 1.2])
    col1_busq = col1.selectbox(
        "B√∫squeda principal por:",
        options=dig_cols if dig_cols else [COL_TITULO],
        index=dig_cols.index(COL_TITULO) if COL_TITULO in dig_cols else 0,
        key="sel_col1"
    )
    col2_busq = col2.selectbox(
        "B√∫squeda complementaria por:",
        options=dig_cols if dig_cols else [COL_TEMATICAS],
        index=dig_cols.index(COL_TEMATICAS) if COL_TEMATICAS in dig_cols else 0,
        key="sel_col2"
    )
    col_dup_dig = col3.selectbox(
        "Columna de duplicados en **Colecci√≥n Digital**",
        options=dig_cols,
        index=dig_cols.index(DEF_DUP_DIGITAL) if DEF_DUP_DIGITAL in dig_cols else 0,
        key="sel_dup_dig"
    )
    col_dup_fis = col4.selectbox(
        "Columna de duplicados en **Colecci√≥n F√≠sica**",
        options=fis_cols,
        index=fis_cols.index(DEF_DUP_FISICA) if DEF_DUP_FISICA in fis_cols else 0,
        key="sel_dup_fis"
    )

    # Plantillas (obligatorias)
    df_temas = None
    df_excluir = None
    if tem_file is not None:
        try:
            df_temas = pd.read_excel(tem_file)
            st.success(f"Tem√°ticas cargadas: {len(df_temas)}")
        except Exception as e:
            st.error(f"Error leyendo Tem√°ticas: {e}")

    if exc_file is not None:
        try:
            df_excluir = pd.read_excel(exc_file)
            st.success(f"T√©rminos a excluir cargados: {len(df_excluir)}")
        except Exception as e:
            st.error(f"Error leyendo T√©rminos a excluir: {e}")

    # Bot√≥n de b√∫squeda
    can_search = (df_temas is not None and not df_temas.empty and
                  df_excluir is not None and not df_excluir.empty and
                  ss.df_digital is not None and ss.df_fisica is not None)

    cols_run = st.columns([1, 3, 1])
    with cols_run[1]:
        btn = st.button("üöÄ Iniciar b√∫squeda", use_container_width=True, disabled=not can_search)

    if btn and can_search:
        with st.status("Ejecutando b√∫squeda (puede tardar)‚Ä¶", expanded=True):
            try:
                ss.processing_digital = True
                res, bit = run_search(
                    ss.df_digital, ss.df_fisica,
                    df_temas, df_excluir,
                    col1_busq=col1_busq,
                    col2_busq=col2_busq,
                    col_dup_dig=col_dup_dig,
                    col_dup_fis=col_dup_fis
                )
                ss.results_df = res
                ss.bitacora_df = bit
                ss.processing_digital = False
                if res.empty:
                    st.warning("B√∫squeda finalizada, sin coincidencias con las tem√°ticas dadas.")
                else:
                    st.success("B√∫squeda finalizada ‚úÖ")
                    st.info(f"Filas resultantes: {len(res)}")
            except Exception as e:
                ss.processing_digital = False
                st.error(f"Ocurri√≥ un error durante la b√∫squeda: {e}")

    # Bit√°cora
    st.markdown("### Bit√°cora")
    if ss.bitacora_df is not None and not ss.bitacora_df.empty:
        st.dataframe(ss.bitacora_df, use_container_width=True, height=220)
    else:
        st.caption("A√∫n no hay bit√°cora disponible.")

    # Resultados con filtros/selecci√≥n/APA
    render_results_ui(ss.results_df)

# -------------------------------------------------------------------------------------

if __name__ == "__main__":
    main()
