# -*- coding: utf-8 -*-
# Herramienta para la elaboraci√≥n de bibliograf√≠as especializadas
# v8.2 ‚Äì Modo A (plantillas) + Modo B (b√∫squeda avanzada), sin tocar el motor base

import io
import os
import time
import tempfile
from typing import List, Dict, Any

import pandas as pd
import requests
import streamlit as st

# ---------------------------------- CONFIGURACI√ìN ----------------------------------
st.set_page_config(page_title="Herramienta de bibliograf√≠as", layout="wide")

LOGO_URL = "https://biblioteca.unbosque.edu.co/sites/default/files/Logos/Logo%201%20Blanco.png"

URL_DIGITAL = "https://biblioteca.unbosque.edu.co/sites/default/files/Formatos-Biblioteca/Biblioteca%20Colecci%C3%B3n%20Digital.xlsx"
URL_FISICA = "https://biblioteca.unbosque.edu.co/sites/default/files/Formatos-Biblioteca/Biblioteca%20BD%20Colecci%C3%B3n%20F%C3%ADsica.xlsx"

URL_PLANTILLA_TEMATICAS = "https://biblioteca.unbosque.edu.co/sites/default/files/Formatos-Biblioteca/Plantilla%20Tem%C3%A1ticas.xlsx"
URL_PLANTILLA_EXCLUSION = "https://biblioteca.unbosque.edu.co/sites/default/files/Formatos-Biblioteca/Plantilla%20T%C3%A9rminos%20a%20excluir.xlsx"

DEFAULT_COL_TITULO = "T√≠tulo"
DEFAULT_COL_TEMATICAS = "Tem√°ticas"
DEFAULT_DUP_DIGITAL = "Url OA"
DEFAULT_DUP_FISICA = "No. Topogr√°fico"

UA = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                  "AppleWebKit/537.36 (KHTML, like Gecko) Chrome Safari"
}

# Columnas a OMITIR en exportaciones CSV/XLSX
EXPORT_DROP_COLS = {
    "Fecha de actualizaci√≥n",
    "Tipo de √≠tem normalizado mat especial",
    "Formato",
    "Prioridad B√∫squeda",
}

# Renombres para exportaci√≥n
EXPORT_RENAME = {
    "Tem√°ticas": "Tem√°ticas catalogadas por el Editor",
    "Tem√°tica": "T√©rmino de b√∫squeda",
    "Tem√°tica normalizada": "T√©rmino de b√∫squeda normalizado",
    "Url en LOCATE/IDEA": "Url de acceso",
}

# ---------------------------------- ESTADO ----------------------------------
ss = st.session_state

# Bases
ss.setdefault("df_digital", None)
ss.setdefault("df_fisica", None)
ss.setdefault("bases_ready", False)

# Descarga
ss.setdefault("downloading", False)
ss.setdefault("descarga_disparada", False)

# Insumos m√©todo A
ss.setdefault("tematicas_df", None)
ss.setdefault("excluir_df", None)

# Resultados
ss.setdefault("results_df", None)
ss.setdefault("bitacora_df", None)

# Modo de b√∫squeda: "A" (plantillas) o "B" (avanzada)
ss.setdefault("modo_busqueda", "A")

# Condiciones para m√©todo B (lista de dicts)
ss.setdefault(
    "condiciones_b",
    [
        {
            "op": "Y",  # operador con la condici√≥n anterior (primera se ignora)
            "campo": "T√≠tulo",
            "modo": "Contiene",
            "valor": "",
        }
    ],
)

# ---------------------------------- UTILIDADES ----------------------------------
def normalize_text(s: Any) -> str:
    if pd.isna(s):
        return ""
    s = str(s)
    return (
        s.replace("\u0301", "")
        .replace("\u0303", "")
        .replace("\u2019", "'")
        .replace("\xa0", " ")
        .strip()
    )


def _head_content_length(url, timeout=30):
    try:
        r = requests.head(url, allow_redirects=True, timeout=timeout, headers=UA)
        r.raise_for_status()
        cl = r.headers.get("Content-Length")
        return int(cl) if cl is not None else None
    except Exception:
        return None


def download_with_resume(
    url, label, container=None, max_retries=5, chunk_size=256 * 1024, timeout=300
) -> io.BytesIO:
    """Descarga con barra y reintentos. Devuelve BytesIO."""
    where = container if container is not None else st
    status = where.empty()
    bar = where.progress(0)
    info = where.empty()

    tmp_dir = tempfile.gettempdir()
    tmp_path = os.path.join(tmp_dir, f"dl_{abs(hash(url))}.part")

    total_size = _head_content_length(url)
    attempt = 0

    while attempt < max_retries:
        attempt += 1
        try:
            downloaded = os.path.getsize(tmp_path) if os.path.exists(tmp_path) else 0
            headers = dict(UA)
            mode = "wb"

            if downloaded and total_size and downloaded < total_size:
                headers["Range"] = f"bytes={downloaded}-"
                mode = "ab"

            status.info(f"Descargando {label}‚Ä¶ (intento {attempt}/{max_retries})")

            with requests.get(
                url,
                stream=True,
                headers=headers,
                timeout=timeout,
                allow_redirects=True,
            ) as r:
                if headers.get("Range") and r.status_code == 200:
                    if os.path.exists(tmp_path):
                        os.remove(tmp_path)
                    downloaded = 0
                    mode = "wb"

                r.raise_for_status()

                content_length = r.headers.get("Content-Length")
                expected_total = downloaded + int(content_length) if content_length else total_size

                last = time.time()
                with open(tmp_path, mode) as f:
                    for chunk in r.iter_content(chunk_size=chunk_size):
                        if not chunk:
                            continue
                        f.write(chunk)
                        downloaded += len(chunk)
                        if expected_total:
                            if time.time() - last > 0.1:
                                bar.progress(min(1.0, downloaded / expected_total))
                                info.write(
                                    f"{downloaded/1e6:,.1f} MB / {expected_total/1e6:,.1f} MB"
                                )
                                last = time.time()

            if total_size and downloaded < total_size:
                raise requests.exceptions.ChunkedEncodingError(
                    f"Descarga incompleta: {downloaded} de {total_size} bytes"
                )

            bar.progress(1.0)
            status.success(f"{label} descargado correctamente.")
            info.empty()
            bar.empty()
            status.empty()

            with open(tmp_path, "rb") as f:
                data = f.read()
            return io.BytesIO(data)

        except Exception as e:
            info.empty()
            bar.empty()
            status.warning(f"Fallo al descargar {label}: {e}")
            if attempt < max_retries:
                time.sleep(2)
            else:
                status.error(
                    f"No se pudo descargar {label} tras {max_retries} intentos."
                )
                raise
        finally:
            info.empty()
            bar.empty()
            status.empty()


def safe_read_excel(bio_or_file, label="archivo") -> pd.DataFrame:
    """
    Lee Excel a DataFrame (openpyxl), dtype=str, sin NaN.
    Adem√°s, limpia espacios en los nombres de columnas.
    """
    try:
        with st.spinner(f"Procesando {label}‚Ä¶"):
            df = pd.read_excel(bio_or_file, engine="openpyxl", dtype=str)
            if not isinstance(df, pd.DataFrame):
                raise ValueError("El archivo no es una hoja de c√°lculo v√°lida.")
            df = df.fillna("")
            df.columns = [str(c).strip() for c in df.columns]
            return df
    except Exception as e:
        raise RuntimeError(f"No fue posible procesar {label}: {e}") from e


def get_index_or_first(options: List[str], value: str) -> int:
    try:
        return options.index(value)
    except Exception:
        return 0


def find_column_by_label(all_columns: List[str], label: str) -> str | None:
    """Busca una columna coincidiendo por nombre normalizado (lower + strip)."""
    target = label.strip().lower()
    for c in all_columns:
        if str(c).strip().lower() == target:
            return c
    return None


def get_value_by_alias(row: pd.Series, label: str) -> str:
    """Devuelve el valor de una columna identificada por label normalizado."""
    target = label.strip().lower()
    for c in row.index:
        if str(c).strip().lower() == target:
            return str(row[c]).strip()
    return ""


# CSS para cambiar "Browse files" ‚Üí "Cargar listado" (mejor esfuerzo)
st.markdown(
    """
<style>
button[title="Browse files"]{visibility: hidden;}
button[title="Browse files"]::after{
    content:" Cargar listado";
    visibility: visible;
    display:inline-block;
    padding:0.25rem 0.75rem;
    background:#2e7d32;
    color:white;
    border-radius:6px;
}
</style>
""",
    unsafe_allow_html=True,
)

# ---------------------------------- SIDEBAR ----------------------------------
with st.sidebar:
    st.image(LOGO_URL, use_container_width=True)
    st.caption(
        "Elaborado por David Camelo para la Biblioteca de la Universidad El Bosque"
    )

    st.markdown("### Plantillas oficiales:")
    st.markdown(f"- [Tem√°ticas]({URL_PLANTILLA_TEMATICAS})")
    st.markdown(f"- [T√©rminos a excluir]({URL_PLANTILLA_EXCLUSION})")

    st.markdown("### Archivos auxiliares (obligatorios, solo Modo A)")
    bloqueados = ss.downloading or (not ss.bases_ready and ss.descarga_disparada)

    tem_up = st.file_uploader(
        "Tem√°ticas (.xlsx, col1=t√©rmino, col2=normalizado)",
        type=["xlsx"],
        key="tem_up_v82",
        disabled=bloqueados,
    )
    exc_up = st.file_uploader(
        "T√©rminos a excluir (.xlsx, col1)",
        type=["xlsx"],
        key="exc_up_v82",
        disabled=bloqueados,
    )

    if not bloqueados:
        if tem_up is not None:
            df = safe_read_excel(tem_up, "Tem√°ticas")
            ss.tematicas_df = (
                df[[df.columns[0], df.columns[1]]]
                .rename(columns={df.columns[0]: "termino", df.columns[1]: "normalizado"})
                .fillna("")
            )
            st.success(f"Tem√°ticas cargadas: {len(ss.tematicas_df)}")
        if exc_up is not None:
            df = safe_read_excel(exc_up, "T√©rminos a excluir")
            ss.excluir_df = (
                df[[df.columns[0]]]
                .rename(columns={df.columns[0]: "excluir"})
                .fillna("")
            )
            st.success(f"T√©rminos a excluir cargados: {len(ss.excluir_df)}")

    st.markdown("---")
    with st.expander("‚ûï Avanzado: subir bases Digital/F√≠sica manualmente", expanded=False):
        up_dig = st.file_uploader(
            "Base de datos de la colecci√≥n Digital (.xlsx)",
            type=["xlsx"],
            key="up_dig_v82",
        )
        up_fis = st.file_uploader(
            "Base de datos de la colecci√≥n F√≠sica (.xlsx)",
            type=["xlsx"],
            key="up_fis_v82",
        )
        if up_dig is not None:
            ss.df_digital = safe_read_excel(up_dig, "Colecci√≥n Digital")
            st.success("Colecci√≥n Digital (manual) cargada.")
        if up_fis is not None:
            ss.df_fisica = safe_read_excel(up_fis, "Colecci√≥n F√≠sica")
            st.success("Colecci√≥n F√≠sica (manual) cargada.")
        if ss.df_digital is not None and ss.df_fisica is not None:
            ss.bases_ready = True

# ---------------------------------- CABECERA ----------------------------------
st.title("Herramienta para la elaboraci√≥n de bibliograf√≠as especializadas")

with st.expander("‚ÑπÔ∏è Informaci√≥n", expanded=True):
    st.markdown(
        f"""
- **Objetivo:** permitir la autogesti√≥n por programa/asignatura/tema y resaltar **t√©rminos a excluir** para depuraci√≥n manual.  
- Usa siempre las bases oficiales (Digital/F√≠sica) o s√∫belas **manualmente** en la barra lateral.  
- **Plantillas:** [Tem√°ticas]({URL_PLANTILLA_TEMATICAS}) y [T√©rminos a excluir]({URL_PLANTILLA_EXCLUSION}).  
- Los archivos adjuntos **no se almacenan** por la Universidad y se eliminan al cerrar la app.  
- El proceso puede tardar algunos minutos; **puedes seguir usando tu equipo** (no cierres el navegador).
        """,
        help="Secci√≥n informativa general.",
    )

with st.expander("üß≠ Paso a paso (recomendado)", expanded=True):
    st.markdown(
        f"""
**1) Sincronizaci√≥n (obligatoria una sola vez por sesi√≥n).**  
Haga clic en **‚ÄúSincronizar bases de datos oficiales‚Äù** (bot√≥n m√°s abajo). Este paso conecta las colecciones **Digital** y **F√≠sica** con su √∫ltima versi√≥n.  
> Este proceso tarda ~5 minutos. No cierre esta ventana.

**2) Modo A (listados) ‚Äì Cargar tem√°ticas.**  
Descargue la plantilla de [Tem√°ticas]({URL_PLANTILLA_TEMATICAS}).  
La **columna 1** incluye variaciones del t√©rmino (con/sin tildes, otros idiomas).  
La **columna 2** agrupa/normaliza el t√©rmino, que ser√° el que ver√°s en los resultados.

**3) Modo A ‚Äì T√©rminos a excluir.**  
Use la plantilla de [T√©rminos a excluir]({URL_PLANTILLA_EXCLUSION}). Sirve para evitar falsos positivos (p. ej., buscar ‚Äúecolog√≠a‚Äù sin recuperar ‚Äúginecolog√≠a‚Äù).

**4) Modo A ‚Äì Par√°metros.**  
Por defecto la b√∫squeda se hace en **T√≠tulo** y **Tem√°ticas** y se eliminan duplicados por **Url OA** (Digital) y **No. Topogr√°fico** (F√≠sica). Puedes cambiarlos si lo necesitas.

**5) Modo B (b√∫squeda avanzada por campos).**  
En el selector de modo, elija **‚ÄúB√∫squeda avanzada (M√©todo B)‚Äù** para definir condiciones por **T√≠tulo, Autor(es), Tem√°ticas, Editorial, A√±o**, etc.  
Puede combinar condiciones con **Y / O / NO** y aplicar filtros por tipo de √≠tem.

**6) Ejecute e interprete.**  
Pulsa **Iniciar b√∫squeda** (Modo A) o **Ejecutar b√∫squeda avanzada** (Modo B).  
Ver√°s una tabla (vista de hasta 200 filas por defecto). Puedes **filtrar**, **marcar filas** y **exportar**.

**7) Nueva b√∫squeda.**  
Pulsa **Nueva b√∫squeda** para cargar otros insumos **sin re-sincronizar** las bases.  
Al cerrar la pesta√±a, la sesi√≥n se pierde (no se guarda nada).
        """
    )

# ---------------------------------- SINCRONIZACI√ìN DE BASES ----------------------------------
st.markdown("#### Bases de datos de las colecciones de la Biblioteca")

if not ss.bases_ready:
    bcol = st.columns([1, 2, 1])[1]
    with bcol:
        btn_sync = st.button(
            "üîÑ Sincronizar bases de datos oficiales",
            type="primary",
            use_container_width=True,
            disabled=ss.downloading or ss.descarga_disparada,
        )
    if btn_sync and not ss.downloading:
        ss.descarga_disparada = True
        ss.downloading = True

    if ss.downloading:
        st.info(
            "Sincronizando colecciones **Digital** y **F√≠sica**‚Ä¶ "
            "Puedes cargar **Tem√°ticas** y **T√©rminos a excluir** mientras tanto. "
            "No cierres esta ventana."
        )

        # Digital
        st.subheader("Descargando Base de datos de la colecci√≥n Digital‚Ä¶")
        zona_dig = st.container()
        try:
            bio_d = download_with_resume(URL_DIGITAL, "Colecci√≥n Digital", container=zona_dig)
            st.caption("Colecci√≥n Digital: descarga completa. Verificando archivo‚Ä¶")
            ss.df_digital = safe_read_excel(bio_d, "Colecci√≥n Digital")
            st.success("Base de datos de la colecci√≥n Digital lista ‚úì")
        except Exception as e:
            st.error(f"No fue posible descargar la base Digital: {e}")
            ss.downloading = False

        # F√≠sica
        st.subheader("Descargando Base de datos de la colecci√≥n F√≠sica‚Ä¶")
        zona_fis = st.container()
        try:
            bio_f = download_with_resume(URL_FISICA, "Colecci√≥n F√≠sica", container=zona_fis)
            st.caption("Colecci√≥n F√≠sica: descarga completa. Verificando archivo‚Ä¶")
            ss.df_fisica = safe_read_excel(bio_f, "Colecci√≥n F√≠sica")
            st.success("Base de datos de la colecci√≥n F√≠sica lista ‚úì")
        except Exception as e:
            st.error(f"No fue posible descargar la base F√≠sica: {e}")
            ss.downloading = False

        if ss.df_digital is not None and ss.df_fisica is not None:
            ss.bases_ready = True
            ss.downloading = False
            st.success("‚úÖ Bases oficiales listas en memoria.")
else:
    st.success("‚úÖ Bases oficiales listas en memoria (sesi√≥n).")
    st.caption(
        "Consejo: usa **Nueva b√∫squeda** para repetir con otras tem√°ticas sin re-sincronizar."
    )

if not ss.bases_ready:
    st.stop()

# ---------------------------------- NUEVA B√öSQUEDA ----------------------------------
col_nb = st.columns([1, 1, 4])[0]
with col_nb:
    if st.button("üß™ Nueva b√∫squeda", use_container_width=True):
        for k in ("tematicas_df", "excluir_df", "results_df", "bitacora_df"):
            ss[k] = None
        # dejamos bases intactas
        st.toast(
            "Listo. Carga nuevas Tem√°ticas/T√©rminos o define nuevas condiciones en el Modo B."
        )

# ---------------------------------- SELECCI√ìN DE MODO ----------------------------------
st.markdown("### Modo de b√∫squeda")

modo_label = st.radio(
    "Elige c√≥mo quieres buscar:",
    (
        "Listado de tem√°ticas (M√©todo A, plantillas)",
        "B√∫squeda avanzada por campos (M√©todo B)",
    ),
    index=0 if ss.modo_busqueda == "A" else 1,
)
ss.modo_busqueda = "A" if "Listado" in modo_label else "B"

# ---------------------------------- MODO A: PLANTILLAS (motor v8.0) ----------------------------------
if ss.modo_busqueda == "A":
    # Validaciones de insumos
    if ss.tematicas_df is None or ss.excluir_df is None:
        st.warning(
            "Para el **M√©todo A** debes cargar **Tem√°ticas** y **T√©rminos a excluir** "
            "en la barra lateral."
        )
        st.stop()

    st.subheader("Configuraci√≥n de b√∫squeda y duplicados (M√©todo A)")

    cols_dig = list(ss.df_digital.columns)
    cols_fis = list(ss.df_fisica.columns)
    common_cols = sorted(set(cols_dig + cols_fis))

    c1, c2, c3, c4 = st.columns([1, 1, 1, 1])

    with c1:
        col_busq1 = st.selectbox(
            "B√∫squeda principal por",
            options=common_cols,
            index=get_index_or_first(common_cols, DEFAULT_COL_TITULO),
            key="col_busq1_v82",
        )

    with c2:
        col_busq2 = st.selectbox(
            "B√∫squeda complementaria por",
            options=common_cols,
            index=get_index_or_first(common_cols, DEFAULT_COL_TEMATICAS),
            key="col_busq2_v82",
        )

    with c3:
        col_dup_dig = st.selectbox(
            "Columna de duplicados en Colecci√≥n Digital",
            options=cols_dig,
            index=get_index_or_first(cols_dig, DEFAULT_DUP_DIGITAL),
            key="dup_dig_v82",
        )

    with c4:
        col_dup_fis = st.selectbox(
            "Columna de duplicados en Colecci√≥n F√≠sica",
            options=cols_fis,
            index=get_index_or_first(cols_fis, DEFAULT_DUP_FISICA),
            key="dup_fis_v82",
        )

    st.caption(
        "Por defecto se usan ‚ÄúT√≠tulo‚Äù y ‚ÄúTem√°ticas‚Äù, y duplicados por ‚ÄúUrl OA‚Äù / "
        "‚ÄúNo. Topogr√°fico‚Äù. Puedes cambiarlo si lo necesitas."
    )

    st.markdown("---")

    # ---- Funciones del motor A ----
    def _prepara_columnas(df: pd.DataFrame, cols: List[str]):
        for c in cols:
            if c in df.columns:
                df[c] = df[c].astype(str).fillna("")

    def _buscar(
        df: pd.DataFrame,
        fuente: str,
        col1: str,
        col2: str,
        tem_df: pd.DataFrame,
        barra,
        estado,
        total_steps: int,
        offset: int,
    ) -> pd.DataFrame:
        res = []
        tem = tem_df.copy()
        tem["termino"] = tem["termino"].astype(str).fillna("")
        tem["normalizado"] = tem["normalizado"].astype(str).fillna("")
        N = len(tem)
        t0 = time.time()

        for i, row in tem.iterrows():
            term = normalize_text(row["termino"])
            if term:
                m1 = df[col1].map(lambda s: term in normalize_text(s))
                m2 = df[col2].map(lambda s: term in normalize_text(s))
                md = df[m1 | m2].copy()
                if not md.empty:
                    md["Tem√°tica"] = row["termino"]
                    md["Tem√°tica normalizada"] = row["normalizado"]
                    md["Columna de coincidencia"] = None
                    md.loc[m1[m1].index, "Columna de coincidencia"] = col1
                    md.loc[m2[m2].index, "Columna de coincidencia"] = md[
                        "Columna de coincidencia"
                    ].fillna(col2)
                    md["Fuente"] = fuente
                    res.append(md)

            frac = (i + 1) / max(N, 1)
            elapsed = time.time() - t0
            est_total = elapsed / max(frac, 1e-6)
            est_rem = max(0, int(est_total - elapsed))
            barra.progress(min(1.0, (offset + i + 1) / total_steps))
            estado.info(
                f"{fuente}: {i+1}/{N} t√©rminos ‚Ä¢ transcurrido: {int(elapsed)} s "
                f"‚Ä¢ restante: {est_rem} s"
            )

        if res:
            return pd.concat(res, ignore_index=True)
        return pd.DataFrame()

    def ejecutar_busqueda_modo_a(
        col_busq1: str, col_busq2: str, col_dup_dig: str, col_dup_fis: str
    ):
        excluye = [
            str(x).strip()
            for x in (ss.excluir_df["excluir"].tolist() if ss.excluir_df is not None else [])
            if str(x).strip() != ""
        ]
        barra = st.progress(0)
        estado = st.empty()

        DF_D = ss.df_digital.copy()
        DF_F = ss.df_fisica.copy()

        _prepara_columnas(DF_D, [col_busq1, col_busq2, col_dup_dig])
        _prepara_columnas(DF_F, [col_busq1, col_busq2, col_dup_fis])

        total = len(ss.tematicas_df) * 2
        res_d = _buscar(
            DF_D,
            "Digital",
            col_busq1,
            col_busq2,
            ss.tematicas_df,
            barra,
            estado,
            total_steps=total,
            offset=0,
        )
        res_f = _buscar(
            DF_F,
            "F√≠sica",
            col_busq1,
            col_busq2,
            ss.tematicas_df,
            barra,
            estado,
            total_steps=total,
            offset=len(ss.tematicas_df),
        )

        if not res_d.empty and col_dup_dig in res_d.columns:
            res_d = res_d.drop_duplicates(subset=[col_dup_dig], keep="first")
        if not res_f.empty and col_dup_fis in res_f.columns:
            res_f = res_f.drop_duplicates(subset=[col_dup_fis], keep="first")

        res = (
            pd.concat([res_d, res_f], ignore_index=True)
            if not (res_d.empty and res_f.empty)
            else pd.DataFrame()
        )

        ss.results_df = res

        tem = (
            ss.tematicas_df[["termino", "normalizado"]]
            .drop_duplicates()
            .reset_index(drop=True)
        )
        fuentes = pd.DataFrame({"Fuente": ["Digital", "F√≠sica"]})
        grid = fuentes.assign(key=1).merge(
            tem.assign(key=1), on="key"
        ).drop("key", axis=1)

        if res.empty:
            counts = pd.DataFrame(
                columns=["Fuente", "Tem√°tica", "Tem√°tica normalizada", "Resultados"]
            )
        else:
            counts = (
                res.groupby(
                    ["Fuente", "Tem√°tica", "Tem√°tica normalizada"], dropna=False
                )
                .size()
                .reset_index(name="Resultados")
            )

        bit = (
            grid.merge(
                counts,
                how="left",
                left_on=["Fuente", "termino", "normalizado"],
                right_on=["Fuente", "Tem√°tica", "Tem√°tica normalizada"],
            )
            .drop(columns=["Tem√°tica", "Tem√°tica normalizada"], errors="ignore")
            .rename(columns={"termino": "T√©rmino", "normalizado": "Normalizado"})
        )

        bit["Resultados"] = bit["Resultados"].fillna(0).astype(int)
        bit = bit.sort_values(
            ["Fuente", "Resultados", "T√©rmino"], ascending=[True, False, True]
        ).reset_index(drop=True)
        ss.bitacora_df = bit

        barra.progress(1.0)
        estado.empty()
        st.success("B√∫squeda finalizada (Modo A).")

    # Bot√≥n de b√∫squeda A
    if st.button("üöÄ Iniciar b√∫squeda (M√©todo A)", type="primary", use_container_width=True):
        try:
            ejecutar_busqueda_modo_a(col_busq1, col_busq2, col_dup_dig, col_dup_fis)
        except Exception as e:
            st.error(f"Ocurri√≥ un problema durante la b√∫squeda: {e}")

# ---------------------------------- MODO B: B√öSQUEDA AVANZADA ----------------------------------
else:
    st.subheader("B√∫squeda avanzada por campos (M√©todo B)")

    all_cols = sorted(
        set(list(ss.df_digital.columns) + list(ss.df_fisica.columns))
    )

    campos_disponibles = [
        "T√≠tulo",
        "Autor(es)",
        "Tem√°ticas",
        "Editorial",
        "A√±o de Publicaci√≥n",
    ]
    modos_disponibles = ["Contiene", "No contiene", "Frase exacta", "Comienza con"]

    st.markdown(
        "Define una o varias condiciones. Puedes combinar con **Y**, **O** o **NO**. "
        "La primera condici√≥n no necesita operador."
    )

    nuevas_cond: List[Dict[str, str]] = []
    for idx, cond in enumerate(ss.condiciones_b):
        col1, col2, col3, col4 = st.columns([0.6, 1.2, 1.2, 3])

        with col1:
            if idx == 0:
                st.markdown("Operador")
                st.caption("‚Äî (primera condici√≥n)")
                op = "Y"
            else:
                op = st.selectbox(
                    "Operador",
                    options=["Y", "O", "NO"],
                    index=get_index_or_first(["Y", "O", "NO"], cond.get("op", "Y")),
                    key=f"op_b_{idx}",
                )

        with col2:
            campo = st.selectbox(
                "Campo",
                options=campos_disponibles,
                index=get_index_or_first(campos_disponibles, cond.get("campo", "T√≠tulo")),
                key=f"campo_b_{idx}",
            )

        with col3:
            modo = st.selectbox(
                "Coincidencia",
                options=modos_disponibles,
                index=get_index_or_first(modos_disponibles, cond.get("modo", "Contiene")),
                key=f"modo_b_{idx}",
            )

        with col4:
            valor = st.text_input(
                "Texto",
                value=cond.get("valor", ""),
                key=f"valor_b_{idx}",
            )

        nuevas_cond.append(
            {"op": op, "campo": campo, "modo": modo, "valor": valor}
        )

    ss.condiciones_b = nuevas_cond

    col_btn1, col_btn2 = st.columns([1, 1])
    with col_btn1:
        if st.button("‚ûï Agregar condici√≥n"):
            ss.condiciones_b.append(
                {"op": "Y", "campo": "T√≠tulo", "modo": "Contiene", "valor": ""}
            )
    with col_btn2:
        if st.button("‚ûñ Quitar √∫ltima condici√≥n") and len(ss.condiciones_b) > 1:
            ss.condiciones_b.pop()

    # Filtro por tipo normalizado
    tipon_col = find_column_by_label(
        all_cols, "Tipo de √≠tem normalizado mat especial"
    )
    filtro_tipo = []
    if tipon_col:
        dfD_t = ss.df_digital.copy()
        dfF_t = ss.df_fisica.copy()
        tipos_opts = sorted(
            set(
                dfD_t.get(tipon_col, pd.Series(dtype=str)).dropna().unique().tolist()
            ).union(
                set(
                    dfF_t.get(tipon_col, pd.Series(dtype=str))
                    .dropna()
                    .unique()
                    .tolist()
                )
            )
        )
        filtro_tipo = st.multiselect(
            "Filtrar por tipo de √≠tem normalizado",
            options=tipos_opts,
            default=[],
        )

    st.markdown("---")

    def ejecutar_busqueda_modo_b(
        condiciones: List[Dict[str, str]], filtro_tipo: List[str]
    ):
        dfD = ss.df_digital.copy()
        dfD["Fuente"] = "Digital"
        dfF = ss.df_fisica.copy()
        dfF["Fuente"] = "F√≠sica"
        base = pd.concat([dfD, dfF], ignore_index=True)

        for c in base.columns:
            base[c] = base[c].astype(str).fillna("")

        if not condiciones:
            st.warning("Debes definir al menos una condici√≥n.")
            return

        # √çndice de columnas normalizadas
        col_map = {str(c).strip().lower(): c for c in base.columns}

        def resolve_col(label: str) -> str | None:
            return col_map.get(label.strip().lower())

        mask = pd.Series(True, index=base.index)
        any_applied = False

        for idx, cond in enumerate(condiciones):
            texto = cond.get("valor", "").strip()
            if not texto:
                continue

            campo_label = cond.get("campo", "T√≠tulo")
            modo = cond.get("modo", "Contiene")
            op = cond.get("op", "Y")

            col_name = resolve_col(campo_label)
            if not col_name:
                continue

            serie = base[col_name].astype(str)

            txt_norm = normalize_text(texto).lower()

            def cmp(v: str) -> bool:
                v_norm = normalize_text(v).lower()
                if modo == "Contiene":
                    return txt_norm in v_norm
                elif modo == "No contiene":
                    return txt_norm not in v_norm
                elif modo == "Frase exacta":
                    return v_norm == txt_norm
                elif modo == "Comienza con":
                    return v_norm.startswith(txt_norm)
                else:
                    return txt_norm in v_norm

            cond_mask = serie.map(cmp)

            if idx == 0:
                mask = cond_mask
            else:
                if op == "Y":
                    mask = mask & cond_mask
                elif op == "O":
                    mask = mask | cond_mask
                elif op == "NO":
                    mask = mask & (~cond_mask)
                else:
                    mask = mask & cond_mask

            any_applied = True

        if not any_applied:
            st.warning("No hay condiciones v√°lidas de b√∫squeda (todas vac√≠as).")
            return

        if filtro_tipo and tipon_col:
            mask = mask & base[tipon_col].isin(filtro_tipo)

        res = base[mask].copy()

        # Aseguramos columnas usadas en filtros posteriores
        for col in ["Tem√°tica", "Tem√°tica normalizada"]:
            if col not in res.columns:
                res[col] = ""

        ss.results_df = res

        # Bit√°cora simple por Fuente
        if res.empty:
            ss.bitacora_df = pd.DataFrame(
                columns=["Fuente", "Resultados"]
            )
        else:
            bit = (
                res.groupby(["Fuente"], dropna=False)
                .size()
                .reset_index(name="Resultados")
                .sort_values(["Fuente"])
                .reset_index(drop=True)
            )
            ss.bitacora_df = bit

        st.success(f"B√∫squeda avanzada finalizada (Modo B). Resultados: {len(res):,}")

    if st.button(
        "üöÄ Ejecutar b√∫squeda avanzada (M√©todo B)",
        type="primary",
        use_container_width=True,
    ):
        try:
            ejecutar_busqueda_modo_b(ss.condiciones_b, filtro_tipo)
        except Exception as e:
            st.error(f"Ocurri√≥ un problema durante la b√∫squeda avanzada: {e}")

# ---------------------------------- RESULTADOS + FILTROS/SELECCI√ìN ----------------------------------
st.subheader("Resultados")

if ss.results_df is None or ss.results_df.empty:
    st.info("A√∫n no hay resultados. Ejecuta la b√∫squeda en el modo que prefieras.")
else:
    res = ss.results_df.copy()

    colf1, colf2, colf3 = st.columns([1, 1, 2])
    with colf1:
        filtro_fuente = st.multiselect(
            "Fuente",
            options=sorted(res["Fuente"].dropna().unique().tolist())
            if "Fuente" in res.columns
            else [],
            default=None,
        )
    with colf2:
        col_tema_norm = "Tem√°tica normalizada"
        temas_norm = (
            sorted(res[col_tema_norm].dropna().unique().tolist())
            if col_tema_norm in res.columns
            else []
        )
        filtro_tema = st.multiselect(
            "Tem√°tica normalizada", options=temas_norm, default=None
        )
    with colf3:
        tipon_col_res = find_column_by_label(
            list(res.columns), "Tipo de √≠tem normalizado mat especial"
        )
        tipo_opts = (
            sorted(
                res.get(tipon_col_res, pd.Series(dtype=str)).dropna().unique().tolist()
            )
            if tipon_col_res
            else []
        )
        filtro_tipo_res = st.multiselect(
            "Tipo normalizado", options=tipo_opts, default=None
        )

    if filtro_fuente:
        res = res[res["Fuente"].isin(filtro_fuente)]
    if filtro_tema and "Tem√°tica normalizada" in res.columns:
        res = res[res["Tem√°tica normalizada"].isin(filtro_tema)]
    if filtro_tipo_res and tipon_col_res:
        res = res[res[tipon_col_res].isin(filtro_tipo_res)]

    st.caption(f"Filas totales (despu√©s de filtros): **{len(res):,}**")

    res_view = res.copy()
    if "__Seleccionar__" not in res_view.columns:
        res_view.insert(0, "__Seleccionar__", False)

    cva, cvb = st.columns([1, 1])
    with cva:
        show_all = st.checkbox("Mostrar todas las filas (Vista)", value=False)
    with cvb:
        limit = st.number_input(
            "Filas a mostrar (Vista)", min_value=50, max_value=10000, value=200, step=50
        )

    res_view_show = res_view if show_all else res_view.head(int(limit))

    res_view_show = st.data_editor(
        res_view_show,
        use_container_width=True,
        height=520,
        column_config={
            "__Seleccionar__": st.column_config.CheckboxColumn("Seleccionar"),
        },
        disabled=[c for c in res_view_show.columns if c != "__Seleccionar__"],
        key="data_editor_res_v82",
    )

    seleccion_mask = (
        res_view_show["__Seleccionar__"]
        if "__Seleccionar__" in res_view_show.columns
        else pd.Series(False, index=res_view_show.index)
    )
    seleccionados = res_view_show[seleccion_mask].drop(
        columns=["__Seleccionar__"], errors="ignore"
    )
    st.caption(f"Seleccionados en la vista: **{len(seleccionados):,}**")

    # --------- Helpers de exportaci√≥n ---------
    def _prep_export(df: pd.DataFrame) -> pd.DataFrame:
        out = df.copy()
        out = out.rename(
            columns={k: v for k, v in EXPORT_RENAME.items() if k in out.columns}
        )
        if "Url en LOCATE/IDEA" in out.columns and "Url de acceso" not in out.columns:
            out = out.rename(columns={"Url en LOCATE/IDEA": "Url de acceso"})
        drop_cols = [c for c in EXPORT_DROP_COLS if c in out.columns]
        if drop_cols:
            out = out.drop(columns=drop_cols)
        return out.fillna("")

    # ---------------------------------- EXPORTACIONES ----------------------------------
    st.markdown("##### Exportaciones")
    colx1, colx2, colx3, colx4, colx5 = st.columns([1.2, 1.2, 1.6, 1.6, 2])

    with colx1:
        st.download_button(
            "‚¨áÔ∏è CSV (todo lo filtrado)",
            data=_prep_export(res).to_csv(index=False).encode("utf-8"),
            file_name="resultados_filtrados.csv",
            mime="text/csv",
            use_container_width=True,
        )

    with colx2:
        st.download_button(
            "‚¨áÔ∏è CSV (solo seleccionados)",
            data=_prep_export(seleccionados if not seleccionados.empty else res.head(0))
            .to_csv(index=False)
            .encode("utf-8"),
            file_name="resultados_seleccionados.csv",
            mime="text/csv",
            disabled=seleccionados.empty,
            use_container_width=True,
        )

    with colx3:
        excluye = []
        if ss.excluir_df is not None:
            excluye = [
                str(x).strip()
                for x in ss.excluir_df.get("excluir", pd.Series(dtype=str)).tolist()
                if str(x).strip() != ""
            ]

        import xlsxwriter

        xbio = io.BytesIO()
        writer = pd.ExcelWriter(xbio, engine="xlsxwriter")

        res_x = _prep_export(res)
        res_x.to_excel(writer, index=False, sheet_name="Resultados")
        wb = writer.book
        ws = writer.sheets["Resultados"]
        fmt = wb.add_format({"bg_color": "#FFF599"})

        cols = list(res_x.columns)

        # Columnas de t√≠tulo y tem√°ticas despu√©s del renombrado
        col_tit_name = (
            EXPORT_RENAME.get(DEFAULT_COL_TITULO, DEFAULT_COL_TITULO)
            if DEFAULT_COL_TITULO in cols
            or EXPORT_RENAME.get(DEFAULT_COL_TITULO, DEFAULT_COL_TITULO) in cols
            else None
        )
        col_tem_name = (
            EXPORT_RENAME.get(DEFAULT_COL_TEMATICAS, DEFAULT_COL_TEMATICAS)
            if DEFAULT_COL_TEMATICAS in cols
            or EXPORT_RENAME.get(DEFAULT_COL_TEMATICAS, DEFAULT_COL_TEMATICAS) in cols
            else None
        )

        col_tit = cols.index(col_tit_name) + 1 if col_tit_name in cols else None
        col_tem = cols.index(col_tem_name) + 1 if col_tem_name in cols else None

        excl_norm = [normalize_text(x) for x in excluye]

        for r in range(1, len(res_x) + 1):
            if col_tit is not None:
                v = normalize_text(res_x.iloc[r - 1, col_tit - 1])
                if any(t in v for t in excl_norm):
                    ws.write(r, col_tit - 1, res_x.iloc[r - 1, col_tit - 1], fmt)
            if col_tem is not None:
                v = normalize_text(res_x.iloc[r - 1, col_tem - 1])
                if any(t in v for t in excl_norm):
                    ws.write(r, col_tem - 1, res_x.iloc[r - 1, col_tem - 1], fmt)

        if ss.bitacora_df is not None and not ss.bitacora_df.empty:
            ss.bitacora_df.to_excel(writer, index=False, sheet_name="Bit√°cora")

        writer.close()
        xbio.seek(0)
        st.download_button(
            "‚¨áÔ∏è Excel (filtrado + resaltado + Bit√°cora)",
            data=xbio.getvalue(),
            file_name="resultados_filtrados.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )

    with colx4:
        if not seleccionados.empty:
            sel_x = _prep_export(seleccionados)
            bio_sel = io.BytesIO()
            with pd.ExcelWriter(bio_sel, engine="xlsxwriter") as wsel:
                sel_x.to_excel(wsel, index=False, sheet_name="Seleccionados")
            bio_sel.seek(0)
            st.download_button(
                "‚¨áÔ∏è Excel (solo seleccionados)",
                data=bio_sel.getvalue(),
                file_name="resultados_seleccionados.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True,
            )
        else:
            st.download_button(
                "‚¨áÔ∏è Excel (solo seleccionados)",
                data=b"",
                file_name="resultados_seleccionados.xlsx",
                disabled=True,
                use_container_width=True,
            )

    def build_apa(row: pd.Series) -> str:
        tit = str(row.get("T√≠tulo", "")).strip()
        aut = get_value_by_alias(row, "Autor(es)")
        edit = str(row.get("Editorial", "")).strip()
        anio = str(row.get("A√±o de Publicaci√≥n", "")).strip()
        bd = str(row.get("Base de datos", "")).strip()
        url = str(row.get("Url OA", "") or row.get("Url de acceso", "")).strip()
        isbn = str(row.get("ISBN", "")).strip()
        issn = str(row.get("ISSN1", "")).strip()
        topog = str(row.get("No. Topogr√°fico", "")).strip()

        partes = []
        if aut and aut.upper() != "NO APLICA":
            partes.append(f"{aut}.")
        if anio and anio.upper() != "NO APLICA":
            partes.append(f"({anio}).")
        if tit:
            partes.append(f"{tit}.")
        if edit:
            partes.append(f"{edit}.")
        elif edit == "":
            partes.append("s.e.")

        acc = []
        if bd:
            acc.append(f"Disponible en {bd}")
        if url:
            acc.append(url)
        if topog and topog.upper() != "NO APLICA":
            acc.append(f"No. Topogr√°fico: {topog}")
        if acc:
            partes.append("; ".join(acc) + ".")

        extras = []
        if isbn and isbn.upper() != "NO APLICA":
            extras.append(f"ISBN: {isbn}")
        if issn and issn.upper() != "NO APLICA":
            extras.append(f"ISSN: {issn}")
        if extras:
            partes.append(" ".join(extras) + ".")

        return " ".join([p for p in partes if p]).replace("..", ".")

    with colx5:
        if not seleccionados.empty:
            citas = [build_apa(r) for _, r in seleccionados.iterrows()]
            txt = "\n\n".join(c for c in citas if c.strip())
            st.download_button(
                "üßæ Citas APA (seleccionados) [beta]",
                data=txt.encode("utf-8"),
                file_name="citas_apa.txt",
                mime="text/plain",
                use_container_width=True,
            )
        else:
            st.download_button(
                "üßæ Citas APA (seleccionados) [beta]",
                data="".encode("utf-8"),
                file_name="citas_apa.txt",
                mime="text/plain",
                use_container_width=True,
                disabled=True,
            )

# ---------------------------------- BIT√ÅCORA ----------------------------------
st.subheader("üìë Bit√°cora")
if ss.bitacora_df is None or ss.bitacora_df.empty:
    st.info("A√∫n no hay bit√°cora. Ejecuta una b√∫squeda para verla.")
else:
    st.dataframe(ss.bitacora_df, use_container_width=True, height=360)
    st.download_button(
        "Descargar bit√°cora (.csv)",
        data=ss.bitacora_df.to_csv(index=False).encode("utf-8"),
        file_name="bitacora_resultados.csv",
        mime="text/csv",
        use_container_width=True,
    )
