# -*- coding: utf-8 -*-
# Herramienta para la elaboraci√≥n de bibliograf√≠as especializadas
# v8.2 ‚Äì M√©todo A estable + M√©todo B avanzado, sin tocar el motor de b√∫squeda original

import io
import os
import time
import tempfile
from typing import List, Dict, Any

import pandas as pd
import requests
import streamlit as st

# ---------------------------------- CONFIGURACI√ìN ----------------------------------
st.set_page_config(page_title="Herramienta de bibliograf√≠as", layout="wide")

# Logos (el tema claro/oscuro lo manejas en config.toml; aqu√≠ s√≥lo usamos uno)
LOGO_URL = "https://biblioteca.unbosque.edu.co/sites/default/files/Logos/Logo%201%20Blanco.png"

# URLs oficiales (Digital/F√≠sica y plantillas)
URL_DIGITAL = "https://biblioteca.unbosque.edu.co/sites/default/files/Formatos-Biblioteca/Biblioteca%20Colecci%C3%B3n%20Digital.xlsx"
URL_FISICA = "https://biblioteca.unbosque.edu.co/sites/default/files/Formatos-Biblioteca/Biblioteca%20BD%20Colecci%C3%B3n%20F%C3%ADsica.xlsx"

URL_PLANTILLA_TEMATICAS = "https://biblioteca.unbosque.edu.co/sites/default/files/Formatos-Biblioteca/Plantilla%20Tem%C3%A1ticas.xlsx"
URL_PLANTILLA_EXCLUSION = "https://biblioteca.unbosque.edu.co/sites/default/files/Formatos-Biblioteca/Plantilla%20T%C3%A9rminos%20a%20excluir.xlsx"

# Valores por defecto para b√∫squeda/duplicados (M√©todo A)
DEFAULT_COL_TITULO = "T√≠tulo"
DEFAULT_COL_TEMATICAS = "Tem√°ticas"
DEFAULT_DUP_DIGITAL = "Url OA"
DEFAULT_DUP_FISICA = "No. Topogr√°fico"

UA = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome Safari"
}

# Columnas a OMITIR en exportaciones CSV/XLSX
EXPORT_DROP_COLS = {
    "Fecha de actualizaci√≥n",
    "Tipo de √≠tem normalizado mat especial",
    "Formato",
    "Prioridad B√∫squeda",
}

# Renombres para exportaci√≥n
EXPORT_RENAME = {
    "Tem√°ticas": "Tem√°ticas catalogadas por el Editor",
    "Tem√°tica": "T√©rmino de b√∫squeda",
    "Tem√°tica normalizada": "T√©rmino de b√∫squeda normalizado",
    "Url en LOCATE/IDEA": "Url de acceso",
}

# ---------------------------------- ESTADO ----------------------------------
ss = st.session_state

# Bases (se conservan toda la sesi√≥n; ‚ÄúNueva b√∫squeda‚Äù no las borra)
ss.setdefault("df_digital", None)
ss.setdefault("df_fisica", None)
ss.setdefault("bases_ready", False)

# Descarga/sincronizaci√≥n
ss.setdefault("downloading", False)
ss.setdefault("descarga_disparada", False)

# Insumos de b√∫squeda (M√©todo A)
ss.setdefault("tematicas_df", None)
ss.setdefault("excluir_df", None)

# Resultados y bit√°cora
ss.setdefault("results_df", None)
ss.setdefault("bitacora_df", None)
ss.setdefault("last_method", None)  # "A" o "B"

# ---------------------------------- UTILIDADES ----------------------------------
def normalize_text(s):
    if pd.isna(s):
        return ""
    s = str(s)
    return (
        s.replace("\u0301", "")
        .replace("\u0303", "")
        .replace("\u2019", "'")
        .replace("\xa0", " ")
        .strip()
    )


def _head_content_length(url, timeout=30):
    try:
        r = requests.head(url, allow_redirects=True, timeout=timeout, headers=UA)
        r.raise_for_status()
        cl = r.headers.get("Content-Length")
        return int(cl) if cl is not None else None
    except Exception:
        return None


def download_with_resume(
    url, label, container=None, max_retries=5, chunk_size=256 * 1024, timeout=300
) -> io.BytesIO:
    """
    Descarga con barra y reintentos. Devuelve BytesIO.
    """
    where = container if container is not None else st
    status = where.empty()
    bar = where.progress(0)
    info = where.empty()

    tmp_dir = tempfile.gettempdir()
    tmp_path = os.path.join(tmp_dir, f"dl_{abs(hash(url))}.part")

    total_size = _head_content_length(url)
    attempt = 0

    while attempt < max_retries:
        attempt += 1
        try:
            downloaded = os.path.getsize(tmp_path) if os.path.exists(tmp_path) else 0
            headers = dict(UA)
            mode = "wb"

            if downloaded and total_size and downloaded < total_size:
                headers["Range"] = f"bytes={downloaded}-"
                mode = "ab"

            status.info(f"Descargando {label}‚Ä¶ (intento {attempt}/{max_retries})")

            with requests.get(
                url,
                stream=True,
                headers=headers,
                timeout=timeout,
                allow_redirects=True,
            ) as r:
                if headers.get("Range") and r.status_code == 200:
                    # el servidor no acept√≥ rango ‚Üí reinicia total
                    if os.path.exists(tmp_path):
                        os.remove(tmp_path)
                    downloaded = 0
                    mode = "wb"

                r.raise_for_status()

                content_length = r.headers.get("Content-Length")
                expected_total = downloaded + int(content_length) if content_length else total_size

                last = time.time()
                with open(tmp_path, mode) as f:
                    for chunk in r.iter_content(chunk_size=chunk_size):
                        if not chunk:
                            continue
                        f.write(chunk)
                        downloaded += len(chunk)
                        if expected_total and time.time() - last > 0.1:
                            bar.progress(min(1.0, downloaded / expected_total))
                            info.write(
                                f"{downloaded/1e6:,.1f} MB / {expected_total/1e6:,.1f} MB"
                            )
                            last = time.time()

            if total_size and downloaded < total_size:
                raise requests.exceptions.ChunkedEncodingError(
                    f"Descarga incompleta: {downloaded} de {total_size} bytes"
                )

            bar.progress(1.0)
            status.success(f"{label} descargado correctamente.")
            info.empty()
            bar.empty()
            status.empty()

            with open(tmp_path, "rb") as f:
                data = f.read()
            return io.BytesIO(data)

        except Exception as e:
            info.empty()
            bar.empty()
            status.warning(f"Fallo al descargar {label}: {e}")
            if attempt < max_retries:
                time.sleep(2)
            else:
                status.error(
                    f"No se pudo descargar {label} tras {max_retries} intentos."
                )
                raise
        finally:
            info.empty()
            bar.empty()
            status.empty()


def safe_read_excel(bio_or_file, label="archivo") -> pd.DataFrame:
    """
    Lee Excel a DataFrame (openpyxl), dtype=str, sin NaN.
    """
    try:
        with st.spinner(f"Procesando {label}‚Ä¶"):
            df = pd.read_excel(bio_or_file, engine="openpyxl", dtype=str)
            if not isinstance(df, pd.DataFrame):
                raise ValueError("El archivo no es una hoja de c√°lculo v√°lida.")
            df = df.fillna("")
            return df
    except Exception as e:
        raise RuntimeError(f"No fue posible procesar {label}: {e}") from e


def get_index_or_first(options: List[str], value: str) -> int:
    try:
        return options.index(value)
    except Exception:
        return 0


def resolve_column(df: pd.DataFrame, canonical: str) -> str:
    """
    Busca una columna cuyo nombre (strip, lower) coincida con el canonical dado.
    √ötil para casos como 'Autor(es) ' con espacio al final.
    """
    target = canonical.strip().lower()
    for c in df.columns:
        if c.strip().lower() == target:
            return c
    return canonical  # si no existe, devolvemos el canonical (se comprobar√° m√°s adelante)


# (Mejor esfuerzo) cambiar el texto ‚ÄúBrowse files‚Äù por ‚ÄúCargar listado‚Äù
st.markdown(
    """
<style>
button[title="Browse files"]{visibility: hidden;}
button[title="Browse files"]::after{
    content:" Cargar listado";
    visibility: visible;
    display:inline-block;
    padding:0.25rem 0.75rem;
    background:#2e7d32;
    color:white;
    border-radius:6px;
}
</style>
""",
    unsafe_allow_html=True,
)

# ---------------------------------- SIDEBAR ----------------------------------
with st.sidebar:
    st.image(LOGO_URL, use_container_width=True)
    st.caption("Elaborado por David Camelo para la Biblioteca de la Universidad El Bosque")

    st.markdown("### Plantillas oficiales:")
    st.markdown(f"- [Tem√°ticas]({URL_PLANTILLA_TEMATICAS})")
    st.markdown(f"- [T√©rminos a excluir]({URL_PLANTILLA_EXCLUSION})")

    st.markdown("### Archivos auxiliares (obligatorios)")
    # Mientras sincroniza bases, congelamos uploaders para evitar re-runs que ‚Äúpierdan‚Äù el archivo
    bloqueados = ss.downloading or (not ss.bases_ready and ss.descarga_disparada)

    tem_up = st.file_uploader(
        "Tem√°ticas (.xlsx, col1=t√©rmino, col2=normalizado)",
        type=["xlsx"],
        key="tem_up_v82",
        disabled=bloqueados,
    )
    exc_up = st.file_uploader(
        "T√©rminos a excluir (.xlsx, col1)",
        type=["xlsx"],
        key="exc_up_v82",
        disabled=bloqueados,
    )

    if not bloqueados:
        if tem_up is not None:
            df = safe_read_excel(tem_up, "Tem√°ticas")
            ss.tematicas_df = df[[df.columns[0], df.columns[1]]].rename(
                columns={df.columns[0]: "termino", df.columns[1]: "normalizado"}
            ).fillna("")
            st.success(f"Tem√°ticas cargadas: {len(ss.tematicas_df)}")
        if exc_up is not None:
            df = safe_read_excel(exc_up, "T√©rminos a excluir")
            ss.excluir_df = df[[df.columns[0]]].rename(
                columns={df.columns[0]: "excluir"}
            ).fillna("")
            st.success(f"T√©rminos a excluir cargados: {len(ss.excluir_df)}")

    st.markdown("---")
    with st.expander("‚ûï Avanzado: subir bases Digital/F√≠sica manualmente", expanded=False):
        up_dig = st.file_uploader(
            "Base de datos de la colecci√≥n Digital (.xlsx)",
            type=["xlsx"],
            key="up_dig_v82",
        )
        up_fis = st.file_uploader(
            "Base de datos de la colecci√≥n F√≠sica (.xlsx)",
            type=["xlsx"],
            key="up_fis_v82",
        )
        if up_dig is not None:
            ss.df_digital = safe_read_excel(up_dig, "Colecci√≥n Digital")
            st.success("Colecci√≥n Digital (manual) cargada.")
        if up_fis is not None:
            ss.df_fisica = safe_read_excel(up_fis, "Colecci√≥n F√≠sica")
            st.success("Colecci√≥n F√≠sica (manual) cargada.")
        if ss.df_digital is not None and ss.df_fisica is not None:
            ss.bases_ready = True

# ---------------------------------- CABECERA ----------------------------------
st.title("Herramienta para la elaboraci√≥n de bibliograf√≠as especializadas")

with st.expander("‚ÑπÔ∏è Informaci√≥n", expanded=True):
    st.markdown(
        f"""
- **Objetivo:** permitir la autogesti√≥n por programa/asignatura/tema y resaltar **t√©rminos a excluir** para depuraci√≥n manual.  
- Usa siempre las bases oficiales (Digital/F√≠sica) o s√∫belas **manualmente** en la barra lateral.  
- **Plantillas:** [Tem√°ticas]({URL_PLANTILLA_TEMATICAS}) y [T√©rminos a excluir]({URL_PLANTILLA_EXCLUSION}).  
- Los archivos adjuntos **no se almacenan** por la Universidad y se eliminan al cerrar la app.  
- El proceso puede tardar algunos minutos; **puedes seguir usando tu equipo** (no cierres el navegador).
        """,
        help="Secci√≥n informativa general.",
    )

with st.expander("üß≠ Paso a paso (recomendado)", expanded=True):
    st.markdown(
        f"""
**1) Sincronizaci√≥n (obligatoria una sola vez por sesi√≥n).**  
Haga clic en **‚ÄúSincronizar bases de datos oficiales‚Äù** (bot√≥n m√°s abajo). Este paso conecta las colecciones **Digital** y **F√≠sica** con su √∫ltima versi√≥n.  
> Este proceso tarda ~5 minutos. No cierre esta ventana.

**2) Cargue sus tem√°ticas (M√©todo A).**  
Descargue la plantilla de [Tem√°ticas]({URL_PLANTILLA_TEMATICAS}).  
La **columna 1** incluye variaciones del t√©rmino (con/sin tildes, otros idiomas).  
La **columna 2** agrupa/normaliza el t√©rmino, que ser√° el que ver√°s en los resultados.

**3) Cargue t√©rminos a excluir (M√©todo A).**  
Use la plantilla de [T√©rminos a excluir]({URL_PLANTILLA_EXCLUSION}). Sirve para evitar falsos positivos (p. ej., buscar ‚Äúecolog√≠a‚Äù sin recuperar ‚Äúginecolog√≠a‚Äù).

**4) Par√°metros de b√∫squeda.**  
Por defecto la b√∫squeda se hace en **T√≠tulo** y **Tem√°ticas** y se eliminan duplicados por **Url OA** (Digital) y **No. Topogr√°fico** (F√≠sica). Puedes cambiarlos si lo necesitas (M√©todo A).

**5) Ejecute e interprete.**  
Pulsa **Iniciar b√∫squeda** (M√©todo A) o **Iniciar b√∫squeda avanzada** (M√©todo B).  
Ver√°s una tabla (vista de hasta 200 filas por defecto).  
Puedes **filtrar**, **marcar filas** y **exportar** en CSV/XLSX o **citas APA** (beta).

**6) Exportaciones.**  
El Excel del M√©todo A incluye la **bit√°cora por t√©rmino** y resalta coincidencias con **t√©rminos a excluir**.  
Las exportaciones ‚Äúsolo seleccionados‚Äù respetan lo marcado en la tabla.

**7) Nueva b√∫squeda.**  
Pulsa **Nueva b√∫squeda** para cargar otras tem√°ticas y t√©rminos **sin re-sincronizar** las bases.  
Al cerrar la pesta√±a, la sesi√≥n se pierde (no se guarda nada).
        """
    )

# ---------------------------------- SINCRONIZACI√ìN DE BASES ----------------------------------
st.markdown("#### Bases de datos de las colecciones de la Biblioteca")

if not ss.bases_ready:
    bcol = st.columns([1, 2, 1])[1]
    with bcol:
        btn_sync = st.button(
            "üîÑ Sincronizar bases de datos oficiales",
            type="primary",
            use_container_width=True,
            disabled=ss.downloading or ss.descarga_disparada,
        )
    if btn_sync and not ss.downloading:
        ss.descarga_disparada = True
        ss.downloading = True

    if ss.downloading:
        st.info(
            "Sincronizando colecciones **Digital** y **F√≠sica**‚Ä¶ "
            "Puedes cargar **Tem√°ticas** y **T√©rminos a excluir** mientras tanto. No cierres esta ventana."
        )

        # Digital
        st.subheader("Descargando Base de datos de la colecci√≥n Digital‚Ä¶")
        zona_dig = st.container()
        try:
            bio_d = download_with_resume(URL_DIGITAL, "Colecci√≥n Digital", container=zona_dig)
            st.caption("Colecci√≥n Digital: descarga completa. Verificando archivo‚Ä¶")
            ss.df_digital = safe_read_excel(bio_d, "Colecci√≥n Digital")
            st.success("Base de datos de la colecci√≥n Digital lista ‚úì")
        except Exception as e:
            st.error(f"No fue posible descargar la base Digital: {e}")
            ss.downloading = False

        # F√≠sica
        st.subheader("Descargando Base de datos de la colecci√≥n F√≠sica‚Ä¶")
        zona_fis = st.container()
        try:
            bio_f = download_with_resume(URL_FISICA, "Colecci√≥n F√≠sica", container=zona_fis)
            st.caption("Colecci√≥n F√≠sica: descarga completa. Verificando archivo‚Ä¶")
            ss.df_fisica = safe_read_excel(bio_f, "Colecci√≥n F√≠sica")
            st.success("Base de datos de la colecci√≥n F√≠sica lista ‚úì")
        except Exception as e:
            st.error(f"No fue posible descargar la base F√≠sica: {e}")
            ss.downloading = False

        if ss.df_digital is not None and ss.df_fisica is not None:
            ss.bases_ready = True
            ss.downloading = False
            st.success("‚úÖ Bases oficiales listas en memoria.")
else:
    st.success("‚úÖ Bases oficiales listas en memoria (sesi√≥n).")
    st.caption("Consejo: usa **Nueva b√∫squeda** para repetir con otras tem√°ticas sin re-sincronizar.")

# Si no hay bases, paramos aqu√≠
if not ss.bases_ready:
    st.stop()

# ---------------------------------- NUEVA B√öSQUEDA ----------------------------------
col_nb = st.columns([1, 1, 4])[0]
with col_nb:
    if st.button("üß™ Nueva b√∫squeda", use_container_width=True):
        for k in ("tematicas_df", "excluir_df", "results_df", "bitacora_df", "last_method"):
            ss[k] = None
        st.toast(
            "Listo. Carga nuevas Tem√°ticas/T√©rminos (M√©todo A) o define condiciones (M√©todo B)."
        )

# ---------------------------------- SELECCI√ìN DE MODO ----------------------------------
modo = st.radio(
    "Modo de b√∫squeda",
    [
        "M√©todo A ‚Äì listado de tem√°ticas",
        "M√©todo B ‚Äì b√∫squeda avanzada (experimental)",
    ],
    horizontal=True,
)

# ---------------------------------- FUNCIONES COMUNES ----------------------------------
def _prepara_columnas(df: pd.DataFrame, cols: List[str]):
    for c in cols:
        if c in df.columns:
            df[c] = df[c].astype(str).fillna("")


def _prep_export(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    # Renombrar columnas espec√≠ficas (si existen)
    out = out.rename(columns={k: v for k, v in EXPORT_RENAME.items() if k in out.columns})
    # Unificar URL de acceso en digital/f√≠sico si aplica
    if "Url en LOCATE/IDEA" in out.columns and "Url de acceso" not in out.columns:
        out = out.rename(columns={"Url en LOCATE/IDEA": "Url de acceso"})
    # Omitir columnas administrativas
    drop_cols = [c for c in EXPORT_DROP_COLS if c in out.columns]
    if drop_cols:
        out = out.drop(columns=drop_cols)
    return out.fillna("")


def build_apa(row: pd.Series) -> str:
    """
    Generador APA simplificado con los campos disponibles.
    Intenta localizar la columna de autor aunque tenga espacios al final.
    """
    tit = str(row.get("T√≠tulo", "")).strip()

    # Buscar columna de autor flexible: "Autor(es)" o similar
    autor_col = None
    for c in row.index:
        if c.strip().lower().startswith("autor"):
            autor_col = c
            break
    aut = str(row.get(autor_col, "")).strip() if autor_col else ""

    edit = str(row.get("Editorial", "")).strip()
    anio = str(row.get("A√±o de Publicaci√≥n", "")).strip()
    bd = str(row.get("Base de datos", "")).strip()
    url = str(row.get("Url OA", "") or row.get("Url de acceso", "")).strip()
    isbn = str(row.get("ISBN", "")).strip()
    issn = str(row.get("ISSN1", "")).strip()
    topog = str(row.get("No. Topogr√°fico", "")).strip()

    partes = []
    if aut and aut.upper() != "NO APLICA":
        partes.append(f"{aut}.")
    if anio and anio.upper() != "NO APLICA":
        partes.append(f"({anio}).")
    if tit:
        partes.append(f"{tit}.")
    if edit:
        partes.append(f"{edit}.")
    elif edit == "":
        partes.append("s.e.")

    acc = []
    if bd:
        acc.append(f"Disponible en {bd}")
    if url:
        acc.append(url)
    if topog and topog.upper() != "NO APLICA":
        acc.append(f"No. Topogr√°fico: {topog}")
    if acc:
        partes.append("; ".join(acc) + ".")

    extras = []
    if isbn and isbn.upper() != "NO APLICA":
        extras.append(f"ISBN: {isbn}")
    if issn and issn.upper() != "NO APLICA":
        extras.append(f"ISSN: {issn}")
    if extras:
        partes.append(" ".join(extras) + ".")

    return " ".join([p for p in partes if p]).replace("..", ".")


# ======================================================================================
#                                     M√âTODO A
#          (Listado de tem√°ticas, motor de b√∫squeda original v8.0 / v8.1)
# ======================================================================================
def metodo_a():
    # Validaciones propias del M√©todo A
    if ss.tematicas_df is None or ss.excluir_df is None:
        st.warning(
            "Para el **M√©todo A** debes cargar **Tem√°ticas** y **T√©rminos a excluir** "
            "en la barra lateral."
        )
        st.stop()

    st.subheader("Configuraci√≥n de b√∫squeda y duplicados (M√©todo A)")

    cols_dig = list(ss.df_digital.columns)
    cols_fis = list(ss.df_fisica.columns)
    common_cols = sorted(set(cols_dig + cols_fis))

    c1, c2, c3, c4 = st.columns([1, 1, 1, 1])

    with c1:
        col_busq1 = st.selectbox(
            "B√∫squeda principal por",
            options=common_cols,
            index=get_index_or_first(common_cols, DEFAULT_COL_TITULO),
            key="col_busq1_v82",
        )

    with c2:
        col_busq2 = st.selectbox(
            "B√∫squeda complementaria por",
            options=common_cols,
            index=get_index_or_first(common_cols, DEFAULT_COL_TEMATICAS),
            key="col_busq2_v82",
        )

    with c3:
        col_dup_dig = st.selectbox(
            "Columna de duplicados en Colecci√≥n Digital",
            options=cols_dig,
            index=get_index_or_first(cols_dig, DEFAULT_DUP_DIGITAL),
            key="dup_dig_v82",
        )

    with c4:
        col_dup_fis = st.selectbox(
            "Columna de duplicados en Colecci√≥n F√≠sica",
            options=cols_fis,
            index=get_index_or_first(cols_fis, DEFAULT_DUP_FISICA),
            key="dup_fis_v82",
        )

    st.caption(
        "Por defecto se usan ‚ÄúT√≠tulo‚Äù y ‚ÄúTem√°ticas‚Äù, y duplicados por ‚ÄúUrl OA‚Äù / ‚ÄúNo. Topogr√°fico‚Äù. "
        "Puedes cambiarlo si lo necesitas."
    )

    st.markdown("---")

    def _buscar(
        df: pd.DataFrame,
        fuente: str,
        col1: str,
        col2: str,
        tem_df: pd.DataFrame,
        barra,
        estado,
        total_steps: int,
        offset: int,
    ) -> pd.DataFrame:
        res = []
        tem = tem_df.copy()
        tem["termino"] = tem["termino"].astype(str).fillna("")
        tem["normalizado"] = tem["normalizado"].astype(str).fillna("")
        N = len(tem)
        t0 = time.time()

        for i, row in tem.iterrows():
            term = normalize_text(row["termino"])
            if term:
                m1 = df[col1].map(lambda s: term in normalize_text(s))
                m2 = df[col2].map(lambda s: term in normalize_text(s))
                md = df[m1 | m2].copy()
                if not md.empty:
                    md["Tem√°tica"] = row["termino"]
                    md["Tem√°tica normalizada"] = row["normalizado"]
                    md["Columna de coincidencia"] = None
                    md.loc[m1[m1].index, "Columna de coincidencia"] = col1
                    md.loc[m2[m2].index, "Columna de coincidencia"] = md[
                        "Columna de coincidencia"
                    ].fillna(col2)
                    md["Fuente"] = fuente
                    res.append(md)

            frac = (i + 1) / max(N, 1)
            elapsed = time.time() - t0
            est_total = elapsed / max(frac, 1e-6)
            est_rem = max(0, int(est_total - elapsed))
            barra.progress(min(1.0, (offset + i + 1) / total_steps))
            estado.info(
                f"{fuente}: {i+1}/{N} t√©rminos ‚Ä¢ transcurrido: {int(elapsed)} s ‚Ä¢ restante: {est_rem} s"
            )

        if res:
            return pd.concat(res, ignore_index=True)
        return pd.DataFrame()

    def ejecutar_busqueda_a():
        excluye = [
            str(x).strip()
            for x in ss.excluir_df["excluir"].tolist()
            if str(x).strip() != ""
        ]
        barra = st.progress(0)
        estado = st.empty()

        DF_D = ss.df_digital.copy()
        DF_F = ss.df_fisica.copy()

        _prepara_columnas(DF_D, [col_busq1, col_busq2, col_dup_dig])
        _prepara_columnas(DF_F, [col_busq1, col_busq2, col_dup_fis])

        total = len(ss.tematicas_df) * 2
        res_d = _buscar(
            DF_D,
            "Digital",
            col_busq1,
            col_busq2,
            ss.tematicas_df,
            barra,
            estado,
            total_steps=total,
            offset=0,
        )
        res_f = _buscar(
            DF_F,
            "F√≠sica",
            col_busq1,
            col_busq2,
            ss.tematicas_df,
            barra,
            estado,
            total_steps=total,
            offset=len(ss.tematicas_df),
        )

        if not res_d.empty and col_dup_dig in res_d.columns:
            res_d = res_d.drop_duplicates(subset=[col_dup_dig], keep="first")
        if not res_f.empty and col_dup_fis in res_f.columns:
            res_f = res_f.drop_duplicates(subset=[col_dup_fis], keep="first")

        res = (
            pd.concat([res_d, res_f], ignore_index=True)
            if not (res_d.empty and res_f.empty)
            else pd.DataFrame()
        )

        # Persistimos
        ss.results_df = res
        ss.last_method = "A"

        # Bit√°cora con ceros
        tem = (
            ss.tematicas_df[["termino", "normalizado"]]
            .drop_duplicates()
            .reset_index(drop=True)
        )
        fuentes = pd.DataFrame({"Fuente": ["Digital", "F√≠sica"]})
        grid = fuentes.assign(key=1).merge(
            tem.assign(key=1), on="key"
        ).drop("key", axis=1)

        if res.empty:
            counts = pd.DataFrame(
                columns=[
                    "Fuente",
                    "Tem√°tica",
                    "Tem√°tica normalizada",
                    "Resultados",
                ]
            )
        else:
            counts = (
                res.groupby(
                    ["Fuente", "Tem√°tica", "Tem√°tica normalizada"], dropna=False
                )
                .size()
                .reset_index(name="Resultados")
            )

        bit = (
            grid.merge(
                counts,
                how="left",
                left_on=["Fuente", "termino", "normalizado"],
                right_on=["Fuente", "Tem√°tica", "Tem√°tica normalizada"],
            )
            .drop(columns=["Tem√°tica", "Tem√°tica normalizada"], errors="ignore")
            .rename(columns={"termino": "T√©rmino", "normalizado": "Normalizado"})
        )

        bit["Resultados"] = bit["Resultados"].fillna(0).astype(int)
        bit = bit.sort_values(
            ["Fuente", "Resultados", "T√©rmino"], ascending=[True, False, True]
        ).reset_index(drop=True)
        ss.bitacora_df = bit

        barra.progress(1.0)
        estado.empty()
        st.success("B√∫squeda finalizada (M√©todo A).")

    # BOT√ìN M√âTODO A
    if st.button("üöÄ Iniciar b√∫squeda (M√©todo A)", type="primary", use_container_width=True):
        try:
            ejecutar_busqueda_a()
        except Exception as e:
            st.error(f"Ocurri√≥ un problema durante la b√∫squeda: {e}")


# ======================================================================================
#                                     M√âTODO B
#                        (B√∫squeda avanzada tipo ‚Äúdescubridor‚Äù)
# ======================================================================================
def metodo_b():
    st.subheader("B√∫squeda avanzada (M√©todo B ‚Äì experimental)")

    # Colecciones a incluir
    c_fuentes, c_tipos = st.columns([1, 1])

    with c_fuentes:
        colecciones = st.multiselect(
            "Colecciones a incluir",
            ["Digital", "F√≠sica"],
            default=["Digital", "F√≠sica"],
        )

    # Tipos normalizados (Libro, Revista, etc.)
    tipo_col = "Tipo de √≠tem normalizado mat especial"
    tipos_all_series = []
    if ss.df_digital is not None and tipo_col in ss.df_digital.columns:
        tipos_all_series.append(ss.df_digital[tipo_col])
    if ss.df_fisica is not None and tipo_col in ss.df_fisica.columns:
        tipos_all_series.append(ss.df_fisica[tipo_col])

    if tipos_all_series:
        tipos_all = (
            pd.concat(tipos_all_series).dropna().astype(str).sort_values().unique().tolist()
        )
    else:
        tipos_all = []

    with c_tipos:
        tipos_sel = st.multiselect(
            "Tipo de √≠tem normalizado",
            options=tipos_all,
            default=tipos_all,  # TODOS seleccionados por defecto
            help="Si no seleccionas nada, se usar√°n todos los tipos disponibles.",
        )

    st.write(
        "Define una o varias condiciones. Se aplican en orden y se combinan "
        "con **Y (AND)**, **O (OR)** o **NO (NOT)**."
    )

    num_cond = st.number_input(
        "N√∫mero de condiciones",
        min_value=1,
        max_value=6,
        value=1,
        step=1,
    )

    CAMPOS = [
        "Cualquier campo",
        "T√≠tulo",
        "Autor(es)",
        "Tem√°ticas",
        "Editorial",
        "A√±o de Publicaci√≥n",
    ]
    OPERADORES = ["Contiene", "No contiene", "Frase exacta", "Comienza con"]

    condiciones: List[Dict[str, Any]] = []
    for i in range(int(num_cond)):
        st.markdown(f"**Condici√≥n {i+1}**")
        c1, c2, c3, c4 = st.columns([0.9, 1.1, 1.0, 1.4])

        with c1:
            if i == 0:
                conector = st.selectbox(
                    "Conector",
                    ["(primera)"],
                    key=f"conn_{i}_v82",
                    disabled=True,
                )
            else:
                conector = st.selectbox(
                    "Conector",
                    ["Y (AND)", "O (OR)", "NO (NOT)"],
                    key=f"conn_{i}_v82",
                )

        with c2:
            campo = st.selectbox(
                "Campo",
                CAMPOS,
                key=f"campo_{i}_v82",
            )

        with c3:
            operador = st.selectbox(
                "Operador",
                OPERADORES,
                key=f"op_{i}_v82",
            )

        with c4:
            valor = st.text_input("Valor", key=f"valor_{i}_v82")

        condiciones.append(
            {
                "conector": conector,
                "campo": campo,
                "operador": operador,
                "valor": valor,
            }
        )

    st.markdown("")
    if st.button("‚úèÔ∏è Iniciar b√∫squeda avanzada (M√©todo B)", use_container_width=True):
        try:
            ejecutar_busqueda_b(
                colecciones=colecciones,
                tipos_sel=tipos_sel,
                condiciones=condiciones,
            )
        except Exception as e:
            st.error(f"Ocurri√≥ un problema durante la b√∫squeda avanzada: {e}")


def _cond_mask_for_df(
    df: pd.DataFrame, campo: str, operador: str, valor: str
) -> pd.Series:
    """
    Construye la m√°scara booleana para una condici√≥n sobre un DataFrame concreto.
    """
    if df.empty or not valor:
        return pd.Series(False, index=df.index)

    valor_norm = str(valor).strip().lower()

    # Resolver columnas "can√≥nicas"
    col_titulo = resolve_column(df, "T√≠tulo")
    col_autor = resolve_column(df, "Autor(es)")
    col_tem = resolve_column(df, "Tem√°ticas")
    col_edit = resolve_column(df, "Editorial")
    col_anio = resolve_column(df, "A√±o de Publicaci√≥n")

    if campo == "T√≠tulo":
        cols = [col_titulo]
    elif campo == "Autor(es)":
        cols = [col_autor]
    elif campo == "Tem√°ticas":
        cols = [col_tem]
    elif campo == "Editorial":
        cols = [col_edit]
    elif campo == "A√±o de Publicaci√≥n":
        cols = [col_anio]
    else:  # Cualquier campo
        cols = [col_titulo, col_autor, col_tem, col_edit, col_anio]

    # Filtrar columnas que realmente existan
    cols = [c for c in cols if c in df.columns]

    if not cols:
        return pd.Series(False, index=df.index)

    base_mask = pd.Series(False, index=df.index)

    for c in cols:
        serie = df[c].astype(str).fillna("").str.lower()
        if operador == "Contiene" or operador == "No contiene":
            m = serie.str.contains(valor_norm, na=False)
        elif operador == "Frase exacta":
            m = serie == valor_norm
        elif operador == "Comienza con":
            m = serie.str.startswith(valor_norm, na=False)
        else:
            m = pd.Series(False, index=df.index)
        base_mask = base_mask | m

    if operador == "No contiene":
        return ~base_mask
    else:
        return base_mask


def ejecutar_busqueda_b(
    colecciones: List[str],
    tipos_sel: List[str],
    condiciones: List[Dict[str, Any]],
):
    frames = []
    tipo_col = "Tipo de √≠tem normalizado mat especial"

    for fuente, df_base in (("Digital", ss.df_digital), ("F√≠sica", ss.df_fisica)):
        if fuente not in colecciones:
            continue
        if df_base is None or df_base.empty:
            continue

        df = df_base.copy()

        # Filtro por tipo normalizado (si hay selecci√≥n)
        if tipos_sel and tipo_col in df.columns:
            df = df[df[tipo_col].isin(tipos_sel)]

        if df.empty:
            continue

        mask_global = None

        for idx, cond in enumerate(condiciones):
            valor = str(cond.get("valor", "")).strip()
            if not valor:
                continue

            campo = cond.get("campo", "Cualquier campo")
            operador = cond.get("operador", "Contiene")
            conector = cond.get("conector", "(primera)")

            cond_mask = _cond_mask_for_df(df, campo, operador, valor)

            if mask_global is None:
                # Primera condici√≥n
                if conector.startswith("NO"):
                    mask_global = ~cond_mask
                else:
                    mask_global = cond_mask
            else:
                if conector.startswith("Y"):
                    mask_global = mask_global & cond_mask
                elif conector.startswith("O"):
                    mask_global = mask_global | cond_mask
                elif conector.startswith("NO"):
                    # Interpretamos NO como "AND NOT" sobre el acumulado
                    mask_global = mask_global & (~cond_mask)
                else:
                    mask_global = mask_global & cond_mask

        if mask_global is None:
            continue

        sub = df[mask_global].copy()
        if sub.empty:
            continue

        sub["Fuente"] = fuente
        frames.append(sub)

    if frames:
        res = pd.concat(frames, ignore_index=True)
    else:
        res = pd.DataFrame()

    # Eliminamos duplicados por Url OA / No. Topogr√°fico si existen
    if not res.empty:
        if DEFAULT_DUP_DIGITAL in res.columns:
            res = res.drop_duplicates(subset=[DEFAULT_DUP_DIGITAL, DEFAULT_DUP_FISICA],
                                      keep="first")

    ss.results_df = res
    ss.bitacora_df = None
    ss.last_method = "B"

    st.success(f"B√∫squeda avanzada finalizada. Resultados: {len(res):,}")


# ======================================================================================
#                  EJECUTAR SEG√öN EL MODO SELECCIONADO (A o B)
# ======================================================================================
if modo.startswith("M√©todo A"):
    metodo_a()
else:
    metodo_b()

# ---------------------------------- RESULTADOS + FILTROS/SELECCI√ìN ----------------------------------
st.subheader("Resultados")

if ss.results_df is None or ss.results_df.empty:
    st.info("A√∫n no hay resultados. Ejecuta la b√∫squeda en el modo seleccionado.")
else:
    res = ss.results_df.copy()

    # Filtros r√°pidos comunes
    colf1, colf2, colf3 = st.columns([1, 1, 2])
    with colf1:
        filtro_fuente = st.multiselect(
            "Fuente",
            options=sorted(res["Fuente"].dropna().unique().tolist())
            if "Fuente" in res.columns
            else [],
            default=None,
        )
    with colf2:
        col_tema_norm = "Tem√°tica normalizada"
        temas_norm = (
            sorted(res[col_tema_norm].dropna().unique().tolist())
            if col_tema_norm in res.columns
            else []
        )
        filtro_tema = st.multiselect(
            "Tem√°tica normalizada",
            options=temas_norm,
            default=None,
        )
    with colf3:
        tipon_col = "Tipo de √≠tem normalizado mat especial"
        tipo_opts = (
            sorted(res.get(tipon_col, pd.Series(dtype=str)).dropna().unique().tolist())
            if tipon_col in res.columns
            else []
        )
        filtro_tipo = st.multiselect(
            "Tipo normalizado",
            options=tipo_opts,
            default=None,
        )

    if filtro_fuente:
        res = res[res["Fuente"].isin(filtro_fuente)]
    if filtro_tema and col_tema_norm in res.columns:
        res = res[res[col_tema_norm].isin(filtro_tema)]
    if filtro_tipo and tipon_col in res.columns:
        res = res[res[tipon_col].isin(filtro_tipo)]

    st.caption(f"Filas totales (despu√©s de filtros): **{len(res):,}**")

    # Columna de selecci√≥n (checkbox)
    res_view = res.copy()
    if "__Seleccionar__" not in res_view.columns:
        res_view.insert(0, "__Seleccionar__", False)

    cva, cvb = st.columns([1, 1])
    with cva:
        show_all = st.checkbox("Mostrar todas las filas (Vista)", value=False)
    with cvb:
        limit = st.number_input(
            "Filas a mostrar (Vista)",
            min_value=50,
            max_value=10000,
            value=200,
            step=50,
        )

    res_view_show = res_view if show_all else res_view.head(int(limit))

    res_view_show = st.data_editor(
        res_view_show,
        use_container_width=True,
        height=520,
        column_config={
            "__Seleccionar__": st.column_config.CheckboxColumn("Seleccionar"),
        },
        disabled=[c for c in res_view_show.columns if c != "__Seleccionar__"],
        key="data_editor_res_v82",
    )

    seleccion_mask = (
        res_view_show["__Seleccionar__"]
        if "__Seleccionar__" in res_view_show.columns
        else pd.Series(False, index=res_view_show.index)
    )
    seleccionados = res_view_show[seleccion_mask].drop(
        columns=["__Seleccionar__"], errors="ignore"
    )
    st.caption(f"Seleccionados en la vista: **{len(seleccionados):,}**")

    # ---------------------------------- EXPORTACIONES ----------------------------------
    st.markdown("##### Exportaciones")

    colx1, colx2, colx3, colx4, colx5 = st.columns([1.2, 1.2, 1.6, 1.6, 2])

    # CSV completo (filtrado)
    with colx1:
        st.download_button(
            "‚¨áÔ∏è CSV (todo lo filtrado)",
            data=_prep_export(res).to_csv(index=False).encode("utf-8"),
            file_name="resultados_filtrados.csv",
            mime="text/csv",
            use_container_width=True,
        )

    # CSV de seleccionados
    with colx2:
        st.download_button(
            "‚¨áÔ∏è CSV (solo seleccionados)",
            data=_prep_export(
                seleccionados if not seleccionados.empty else res.head(0)
            ).to_csv(index=False).encode("utf-8"),
            file_name="resultados_seleccionados.csv",
            mime="text/csv",
            disabled=seleccionados.empty,
            use_container_width=True,
        )

    # Excel completo / resaltado + Bit√°cora SOLO para M√©todo A
    with colx3:
        if ss.last_method == "A":
            excluye = [
                str(x).strip()
                for x in ss.excluir_df["excluir"].tolist()
                if str(x).strip() != ""
            ]
            import xlsxwriter

            xbio = io.BytesIO()
            writer = pd.ExcelWriter(xbio, engine="xlsxwriter")

            res_x = _prep_export(res)
            res_x.to_excel(writer, index=False, sheet_name="Resultados")
            wb = writer.book
            ws = writer.sheets["Resultados"]
            fmt = wb.add_format({"bg_color": "#FFF599"})

            cols = list(res_x.columns)
            # Localizar columnas de t√≠tulo y tem√°ticas despu√©s de renombres
            try:
                col_tit_idx = cols.index(
                    EXPORT_RENAME.get(DEFAULT_COL_TITULO, DEFAULT_COL_TITULO)
                )
            except ValueError:
                try:
                    col_tit_idx = cols.index(DEFAULT_COL_TITULO)
                except ValueError:
                    col_tit_idx = None

            try:
                col_tem_idx = cols.index(
                    EXPORT_RENAME.get(DEFAULT_COL_TEMATICAS, DEFAULT_COL_TEMATICAS)
                )
            except ValueError:
                try:
                    col_tem_idx = cols.index(DEFAULT_COL_TEMATICAS)
                except ValueError:
                    col_tem_idx = None

            excl_norm = [normalize_text(x) for x in excluye]

            for r in range(1, len(res_x) + 1):
                if col_tit_idx is not None:
                    v = normalize_text(res_x.iloc[r - 1, col_tit_idx])
                    if any(t in v for t in excl_norm):
                        ws.write(r, col_tit_idx, res_x.iloc[r - 1, col_tit_idx], fmt)
                if col_tem_idx is not None:
                    v = normalize_text(res_x.iloc[r - 1, col_tem_idx])
                    if any(t in v for t in excl_norm):
                        ws.write(r, col_tem_idx, res_x.iloc[r - 1, col_tem_idx], fmt)

            if ss.bitacora_df is not None:
                ss.bitacora_df.to_excel(
                    writer, index=False, sheet_name="Bit√°cora"
                )

            writer.close()
            xbio.seek(0)
            st.download_button(
                "‚¨áÔ∏è Excel (filtrado + resaltado + Bit√°cora)",
                data=xbio.getvalue(),
                file_name="resultados_filtrados.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True,
            )
        else:
            # M√©todo B: Excel simple con los resultados filtrados
            bio_all = io.BytesIO()
            with pd.ExcelWriter(bio_all, engine="xlsxwriter") as w_all:
                _prep_export(res).to_excel(w_all, index=False, sheet_name="Resultados")
            bio_all.seek(0)
            st.download_button(
                "‚¨áÔ∏è Excel (todo lo filtrado)",
                data=bio_all.getvalue(),
                file_name="resultados_filtrados.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True,
            )

    # Excel de seleccionados (sin resaltado)
    with colx4:
        if not seleccionados.empty:
            sel_x = _prep_export(seleccionados)
            bio_sel = io.BytesIO()
            with pd.ExcelWriter(bio_sel, engine="xlsxwriter") as wsel:
                sel_x.to_excel(wsel, index=False, sheet_name="Seleccionados")
            bio_sel.seek(0)
            st.download_button(
                "‚¨áÔ∏è Excel (solo seleccionados)",
                data=bio_sel.getvalue(),
                file_name="resultados_seleccionados.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True,
            )
        else:
            st.download_button(
                "‚¨áÔ∏è Excel (solo seleccionados)",
                data=b"",
                file_name="resultados_seleccionados.xlsx",
                disabled=True,
                use_container_width=True,
            )

    # Citas APA (beta) sobre seleccionados
    with colx5:
        if not seleccionados.empty:
            citas = [build_apa(r) for _, r in seleccionados.iterrows()]
            txt = "\n\n".join(c for c in citas if c.strip())
            st.download_button(
                "üßæ Citas APA (seleccionados)",
                data=txt.encode("utf-8"),
                file_name="citas_apa.txt",
                mime="text/plain",
                use_container_width=True,
            )
        else:
            st.download_button(
                "üßæ Citas APA (seleccionados)",
                data="".encode("utf-8"),
                file_name="citas_apa.txt",
                mime="text/plain",
                use_container_width=True,
                disabled=True,
            )

# ---------------------------------- BIT√ÅCORA ----------------------------------
st.subheader("üìë Bit√°cora por t√©rmino")

if ss.last_method != "A":
    st.info(
        "La bit√°cora detallada se genera √∫nicamente con el **M√©todo A (listado de tem√°ticas)**."
    )
elif ss.bitacora_df is None or ss.bitacora_df.empty:
    st.info("A√∫n no hay bit√°cora. Ejecuta la b√∫squeda con el **M√©todo A**.")
else:
    st.dataframe(ss.bitacora_df, use_container_width=True, height=360)
    st.download_button(
        "Descargar bit√°cora (.csv)",
        data=ss.bitacora_df.to_csv(index=False).encode("utf-8"),
        file_name="bitacora_por_termino.csv",
        mime="text/csv",
        use_container_width=True,
    )
